{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.소프트맥스회귀.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1yAb_31XviEPbgRioDJPTmyk4kMOjWCe1",
      "authorship_tag": "ABX9TyOdw2SCZ7acXHQnG5mwDZg/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8ac8771f4d344deda66b645543f259ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7c720824cc82454c808b74160377fe31",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_16c342965a7b4accba92f4ec2fa506b1",
              "IPY_MODEL_2503fbffcbd04f2d85f894a46e088188"
            ]
          }
        },
        "7c720824cc82454c808b74160377fe31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16c342965a7b4accba92f4ec2fa506b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7e34a9e3112849f196d3efb7523b1a3d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf7cf43286664bf7a804e2ed99c89798"
          }
        },
        "2503fbffcbd04f2d85f894a46e088188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce7617063d3d4adf80c29bf7de7bac19",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:19&lt;00:00, 2015478.67it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d786102db9e4ac6b6e303214bbb7bf9"
          }
        },
        "7e34a9e3112849f196d3efb7523b1a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf7cf43286664bf7a804e2ed99c89798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce7617063d3d4adf80c29bf7de7bac19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d786102db9e4ac6b6e303214bbb7bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3f8634577b54cd0b0f6b9748f7ab8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0274179daf9044a5ba92d4759f2ff866",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_11fd883df4fa4367923aae455d1f4f09",
              "IPY_MODEL_9033e945e6d74836adc8027aa63d8aa9"
            ]
          }
        },
        "0274179daf9044a5ba92d4759f2ff866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11fd883df4fa4367923aae455d1f4f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6832aee30f22483794b63adf8c5a46a9",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09a16b2e401f4b2d91534e47451c0c0f"
          }
        },
        "9033e945e6d74836adc8027aa63d8aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8270fda94454453bebfca2a1b7e6cf3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/28881 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b249455092cb42f199e701cecca76379"
          }
        },
        "6832aee30f22483794b63adf8c5a46a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09a16b2e401f4b2d91534e47451c0c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8270fda94454453bebfca2a1b7e6cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b249455092cb42f199e701cecca76379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72dd680eef274d1fbd534aa53c4e712d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b7421a34fc4c4b6fbf2f1e103813051f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0ce633a1ddd4fe6b485fa8601d6240c",
              "IPY_MODEL_91bc172650e549f9a92f2f66f9962507"
            ]
          }
        },
        "b7421a34fc4c4b6fbf2f1e103813051f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0ce633a1ddd4fe6b485fa8601d6240c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_946a03f4cccb4ee09a911021f268c3d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d73277eb273b4855b88b1e95ca0dd636"
          }
        },
        "91bc172650e549f9a92f2f66f9962507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b441ad75145543e6a60166733a481279",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:18&lt;00:00, 391918.94it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7f50952210344faabaacc2c167c9194"
          }
        },
        "946a03f4cccb4ee09a911021f268c3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d73277eb273b4855b88b1e95ca0dd636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b441ad75145543e6a60166733a481279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7f50952210344faabaacc2c167c9194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1180aecfa75844c7ac2f464ae35a3b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c076a71b525643fdb05d75f7bf3cd45b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3fa3af524073408388a810a0b286862b",
              "IPY_MODEL_5c12749db0564fedb380628ce405c89d"
            ]
          }
        },
        "c076a71b525643fdb05d75f7bf3cd45b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fa3af524073408388a810a0b286862b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_519f459e279e410c80f2538124bea29f",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30fda7e772d24a7aa9edb39626bc6d06"
          }
        },
        "5c12749db0564fedb380628ce405c89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33edbb70c4274c6daf627d19c9b26ae2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/4542 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b4fc943766847ad8d36952e79580d0d"
          }
        },
        "519f459e279e410c80f2538124bea29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30fda7e772d24a7aa9edb39626bc6d06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33edbb70c4274c6daf627d19c9b26ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b4fc943766847ad8d36952e79580d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jung0Jin/Pytorch_study/blob/master/4.%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFI8ENNh_4HO"
      },
      "source": [
        "2021년 1월 11일"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiqLac1VzHi6"
      },
      "source": [
        "출처 : https://wikidocs.net/59425\n",
        "\n",
        "참고 : https://github.com/Namsik-Yoon/pytorch_basic/blob/master/4.%20%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4%20%ED%9A%8C%EA%B7%80(Softmax_Regression).ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqZ_SeA4zOEu"
      },
      "source": [
        "#4. 소프트맥스 회귀(Softmax Regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZbsPYWh1YKY"
      },
      "source": [
        "##4.1 원-핫 인코딩(One-Hot Encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AAvwowv-Zkm"
      },
      "source": [
        "범주형 데이터를 처리할 때 레이블을 표현하는 방법인 원-핫 인코딩에 대해 배우자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctf2Sgo9-cfo"
      },
      "source": [
        "###4.1.1 원-핫 인코딩이란?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSmt9oTb1rKP"
      },
      "source": [
        "원-핫 인코딩은 선택지의 개수만큼의 차원을 가지면서, 각 선택지의 인덱스에 해당하는 원소에 1, 나머지 원소는 0의 값을 가지도록 하는 표현 방법이다.\n",
        "\n",
        "예를 들어 강아지, 고양이, 냉장고가 있다하자.\n",
        "\n",
        "강아지 = [1, 0, 0]\n",
        "\n",
        "고양이 = [0, 1, 0]\n",
        "\n",
        "냉장고 = [0, 0, 1]\n",
        "\n",
        "로 표현하는게 원-핫 인코딩이다. 이 벡터들을 원-핫 벡터라고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kVWqOEk-gl0"
      },
      "source": [
        "###4.1.2 원-핫 벡터의 무작위성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtzT3hhw2MlC"
      },
      "source": [
        "범주형 데이터가 각 데이터 간의 관계가 균등하다는 점에서 원-핫 벡터는 적절한 표현 방법이다.\n",
        "\n",
        "다중 클래스 분류 문제도 각 클래스 간의 관계가 균등하다는 점에서 적절한 표현 방법이다.\n",
        "\n",
        "예를 들어 강아지, 고양이, 냉장고를 정수 인코딩 (0, 1, 2) 으로  레이블 한다면, 강아지와 고양이 사이의 관계(1-0 = 1)가 강아지와 냉장고 사이의 관계(2-0 = 2)보다 가깝다고 생각될 수 있다.\n",
        "\n",
        "클래스 간의 관계가 균등하기 때문에 특정 클래스가 가깝다고 여겨지는 정수 인코딩보다 원-핫 인코딩이 클래스의 성질을 잘 표현했다고 할 수 있다.\n",
        "\n",
        "이걸 아래의 식인 MSE를 사용하여 확인해보자.\n",
        "\n",
        "$Loss\\ function = \\frac{1}{n} \\sum_i^{n} \\left(y_{i} - \\hat{y_{i}}\\right)^2$\n",
        "\n",
        "강아지, 고양이, 냉장고라는 3개의 클래스를 각각 0, 1, 2 로 정수 인코딩한다.\n",
        "\n",
        "실제값이 강아지, 예측값이 고양이면 MSE는 다음과 같다.\n",
        "\n",
        "$(1-0)^{2} = 1$\n",
        "\n",
        "실제값이 강아지, 예측값이 냉장고면 MSE는 다음과 같다.\n",
        "\n",
        "$(2-0)^{2} = 4$\n",
        "\n",
        "오차의 값이 다르다. 즉, 이는 기계에게 강아지가 냉장고보다 고양이에 가깝다는 정보를 주는 것과 다름 없다.\n",
        "\n",
        "더 많은 클래스에 대해 정수 인코딩을 수행하면? 난리난다.\n",
        "\n",
        "정리하겠다. 정수 인코딩과 달리 원-핫 인코딩은 분류 문제에서 모든 클래스 간의 관계를 균등하게 분배한다.\n",
        "\n",
        "원-핫 인코딩을 했을 때의 MSE를 보겠다.\n",
        "\n",
        "$((1,0,0)-(0,1,0))^{2} = (1-0)^{2} + (0-1)^{2} + (0-0)^{2} = 2$\n",
        "\n",
        "$((1,0,0)-(0,0,1))^{2} = (1-0)^{2} + (0-0)^{2} + (0-1)^{2} = 2$\n",
        "\n",
        "원-핫 인코딩은 클래스의 관계를 균등하기 만들기 때문에 원-핫벡터는 무작위성을 가진다. 각 클래스를 인코딩 할 때 표현 방법이 무작위하다는 것이다. 예를 들어 강아지가 (1,0,0) 일지 (0,1,0) 일지 (0,0,1) 일지 모른다. 이러한 원-핫 벡터의 무작위성은 때로는 단어의 유사성을 구할 수 없다는 단점으로 언급되기도 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjlY2qp-ric"
      },
      "source": [
        "## 4.2 소프트맥스 회귀 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cOXMRLf5o-x"
      },
      "source": [
        "로지스틱 회귀 : 2개 중 1개 고르는 이진 분류\n",
        "\n",
        "소프트맥스 회귀 : 3개 이상 중 1개 고르는 다증 클래스 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AjXQoMu-vbT"
      },
      "source": [
        "###4.2.1 다중 클래스 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO2iqi7v8XjZ"
      },
      "source": [
        "아래는 꽃받침 길이, 꽃받침 넓이, 꽃잎 길이, 꽃잎 넓이라는 4개의 특성(feature)로부터 setosa, versicolor, virginica 라는 3개의 붓꽃 품종을 예측하는 문제이다.\n",
        "\n",
        "|SepalLengthCm$(x_1)$|SepalWidthCm$(x_2)$|PetalLengthCm$(x_3)$|PetalWidthCm$(x_4)$|Species$(y)$|\n",
        "|---|---|---|---|---|\n",
        "|5.1|3.5|1.4|0.2|setosa|\n",
        "|4.9|3.0|1.4|0.2|setosa|\n",
        "|5.8|2.6|4.0|1.2|versicolor|\n",
        "|6.7|3.0|5.2|2.3|virginica|\n",
        "|5.6|2.8|4.9|2.0|virginica|\n",
        "\n",
        "이번 챕터의 설명에서 입력은 $X$, 가중치는 $W$, 편향은 $B$, 출력은 $\\hat{Y}$로 각 변수는 벡터 또는 행렬로 가정한다.\n",
        "\n",
        "*   $\\hat{Y}$은 예측값이라는 의미를 가지고 있으므로 가설식에서 $H(X)$ 대신 사용되기도 한다.\n",
        "\n",
        "1) 로지스틱 회귀\n",
        "\n",
        "로지스틱 회귀에서 시그모이드 함수는 예측값을 0과 1사이의 값으로 만든다.\n",
        "\n",
        "예를 들어 스팸 메일 분류기를 로지스틱 회귀로 구현하면, 출력이 0.75라면 스팸일 확률이 75%라는 의미가 된다. 동시에, 스팸이 아닐 확률이 25%가 된다.\n",
        "\n",
        "![대체 텍스트](https://camo.githubusercontent.com/acee24af0ee38fcf4de25f774073d702ad289194/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f35393432372f2545422541312539432545432541372538302545432538412541342545442538422542312545442539412538432545412542372538302e504e47)\n",
        "\n",
        "가설 : $H(X) = sigmoid(WX + B)$\n",
        "\n",
        "2) 소프트맥스 회귀\n",
        "\n",
        "소프트맥스 회귀에서 소프트맥스 함수는 예측값을 0과 1사이의 값으로 만든다.\n",
        "\n",
        "선택지의 개수만큼의 차원을 가지는 벡터를 만들고, 모든 원소의 합이 1이 되도록 원소들의 값을 변환시키는 소프트맥스 함수를 지나게 만들어야 한다.\n",
        "\n",
        "![대체 텍스트](https://camo.githubusercontent.com/2be4df15c4c65877caf65dced6533ed34009e39e/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f35393432372f2545432538362538432545442539342538342545442538412542382545422541372541352545432538412541342545442539412538432545412542372538302e504e47)\n",
        "\n",
        "가설 : $H(X) = softmax(WX + B)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E82Hebqi-4Ca"
      },
      "source": [
        "###4.2.2 소프트맥스 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idz6bGMl__cE"
      },
      "source": [
        "소프트맥스 함수는 클래스의 개수(k라고 하자)만큼의 차원을 가진 벡터를 입력받아 각 클래스에 대한 확률을 추정한다.\n",
        "\n",
        "1) 소프트맥스 함수의 이해\n",
        "\n",
        "k차원의 벡터에서 i번째 원소를 $z_i$, i번째 클래스가 정답일 확률을 $p_i$로 나타낸다고 하였을 때 소프트맥스 함수는 $p_i$를 다음과 같이 정의한다.\n",
        "\n",
        "$p_{i}=\\frac{e^{z_{i}}}{\\sum_{j=1}^{k} e^{z_{j}}}\\ \\ for\\ i=1, 2, ... k$\n",
        "\n",
        "![대체 텍스트](https://camo.githubusercontent.com/2be4df15c4c65877caf65dced6533ed34009e39e/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f35393432372f2545432538362538432545442539342538342545442538412542382545422541372541352545432538412541342545442539412538432545412542372538302e504e47)\n",
        "\n",
        "위에서 풀어야하는 문제에 소프트맥스 함수를 차근차근 적용해보자. 문제의 경우 k=3이므로 3차원 벡터 $z=[z_{1}\\ z_{2}\\ z_{3}]$의 입력을 받으면 소프트맥스 함수는 아래와 같은 출력을 리턴한다.\n",
        "\n",
        "$softmax(z)=[\\frac{e^{z_{1}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{2}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{3}}}{\\sum_{j=1}^{3} e^{z_{j}}}] = [p_{1}, p_{2}, p_{3}] = \\hat{y} = \\text{예측값}$\n",
        "\n",
        "$p_1,p_2,p_3$  각각은 1번 클래스가 정답일 확률, 2번 클래스가 정답일 확률, 3번 클래스가 정답일 확률을 나타내며 각각 0과 1사이의 값으로 총 합은 1이 된다.\n",
        "\n",
        "여기서 분류하고자하는 3개의 클래스는 virginica, setosa, versicolor이므로 이는 결국 주어진 입력이 virginica일 확률, setosa일 확률, versicolor일 확률을 나타내는 값을 의미한다.\n",
        "\n",
        "여기서는 i가 1일 때는 virginica일 확률을 나타내고, 2일 때는 setosa일 확률, 3일때는 versicolor일 확률이라고 지정하였다고 하자. 이 지정 순서는 문제를 풀고자 하는 사람의 무작위 선택이다. 이에따라 식을 문제에 맞게 다시 쓰면 아래와 같다.\n",
        "\n",
        "$softmax(z)=[\\frac{e^{z_{1}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{2}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{3}}}{\\sum_{j=1}^{3} e^{z_{j}}}] = [p_{1}, p_{2}, p_{3}] = [p_{virginica}, p_{setosa}, p_{versicolor}]$\n",
        "\n",
        "정리 : 분류하고자 하는 클래스가 k개이면, k차원의 벡터를 입력받아서 벡터의 모든 원소의 값을 0과 1사이의 값으로 변경하고, 다시 k차원의 벡터를 리턴하면 된다.\n",
        "\n",
        "2) 그림을 통한 이해\n",
        "\n",
        "![](https://camo.githubusercontent.com/a6ede60782b3f8d590aca00e9e765ea5ec732afb/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33353437362f736f66746d6178315f66696e616c5f66696e616c2e504e47)\n",
        "\n",
        "질문 1 : 샘플 데이터를 소프트맥스 함수의 입력으로 어떻게 바꿀까?\n",
        "\n",
        "|SepalLengthCm$(x_1)$|SepalWidthCm$(x_2)$|PetalLengthCm$(x_3)$|PetalWidthCm$(x_4)$|Species$(y)$|\n",
        "|---|---|---|---|---|\n",
        "|5.1|3.5|1.4|0.2|setosa|\n",
        "|4.9|3.0|1.4|0.2|setosa|\n",
        "|5.8|2.6|4.0|1.2|versicolor|\n",
        "|6.7|3.0|5.2|2.3|virginica|\n",
        "|5.6|2.8|4.9|2.0|virginica|\n",
        "\n",
        "여기서 샘플 데이터를 1개씩 입력으로 받아 처리한다고 가정하자. 샘플 데이터가 1개씩 처리된다는 것은 배치 크기가 1이라는 것과 같은 의미다. 하나의 샘플 데이터는 4개의 독립 변수 $x$를 가지는데 이는 모델이 4차원 벡터를 입력으로 받음을 의미한다.\n",
        "\n",
        "4차원 벡터가 모델로 입력된 다음 단계는 소프트맥스 함수에 입력되는 것이다.\n",
        "\n",
        "모델에 입력된 벡터는 4차원이고, 소프트맥스 함수에 입력될 수 있는 벡터는 3차원이다.\n",
        "\n",
        "따라서, 입력된 4차원 벡터는 다시 어떤 가중치 연산을 통해 분류하고자 하는 클래스의 개수인 3차원 벡터로 변환되어야 한다. \n",
        "\n",
        "그래야 소프트맥스 함수의 입력으로 쓸 수 있다.\n",
        "\n",
        "아래 그림에서는 소프트맥스 함수의 입력으로 사용되는 3차원 벡터를 $z$로 표현했다.\n",
        "\n",
        "![](https://camo.githubusercontent.com/172a4d05ef2b15ec46c642dc195caf7fa97f047b/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33353437362f736f66746d61786265747765656e31616e64322e504e47)\n",
        "\n",
        "샘플 데이터 벡터(4차원)를 소프트맥스 함수의 입력 벡터(3차원)로 변환하는 방법은 소프트맥스 함수의 입력 벡터 $z$의 차원수만큼 결과값이 나오도록 가중치 곱을 진행하는 것이다.\n",
        "\n",
        "즉 (4 x 3 = 12) 12개의 전부 다른 가중치로 학습 과정에서 점차적으로 오차를 최소화하면 된다.\n",
        "\n",
        "질문 2 : 오차를 어떻게 구할까?\n",
        "\n",
        "여기서는 첫번째 원소인 $p_1$은 virginica가 정답일 확률, 두번째 원소인 $p_2$는 setosa가 정답일 확률, 세번째 원소인 $p_3$은 versicolor가 정답일 확률로 고려한다. 그렇다면 이 예측값과 비교를 할 수 있는 실제값의 표현 방법이 있어야 한다. 소프트맥스 회귀에서는 실제값을 원-핫 벡터로 표현한다. 아래 그림은 원-핫 인코딩을 수행하여 실제값을 원-핫 벡터로 수치화한 것을 보여준다.\n",
        "\n",
        "![](https://camo.githubusercontent.com/e57ce45ea8db9548650e711170568fd662b3d067/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33353437362f736f66746d6178325f66696e616c2e504e47)\n",
        "\n",
        "현재 풀고 있는 샘플 데이터의 실제값이 setosa라면 setosa의 원-핫 벡터는 [0,1,0]이다. 이 두 벡터의 오차를 계산하기 위해서 소프트맥스 회귀는 비용 함수로 크로스 엔트로피 함수를 사용한다.\n",
        "\n",
        "![](https://camo.githubusercontent.com/5af606fdacad2a5d610b760eaad071314945e153/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33353437362f736f66746d6178342e504e47)\n",
        "\n",
        "![](https://camo.githubusercontent.com/b07ec8f666e2c2e3490c7f6a0da57a3ad3d5701e/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33353437362f736f66746d6178352e504e47)\n",
        "\n",
        "![](https://camo.githubusercontent.com/92fb01a7238490aad23863f2b331ffdcc9ccba0b/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f33353437362f736f66746d6178365f66696e616c2e504e47)\n",
        "\n",
        "이런식으로 앞서 배운 선형 회귀나 로지스틱 회귀와 마찬가지로 오차로부터 가중치를 업데이트 한다.\n",
        "\n",
        "소프트맥스 회귀를 벡터와 행렬 연산으로 이해해보자. \n",
        "\n",
        "입력 : 특성(feature)의 수만큼의 차원을 가진 입력 벡터 $x$\n",
        "\n",
        "가중치 :  $W$\n",
        "\n",
        "편향 : $B$\n",
        "\n",
        "소프트맥스 회귀에서 예측값을 구하는 과정을 벡터와 행렬 연산으로 표현하면 아래와 같다.\n",
        "\n",
        "![](https://camo.githubusercontent.com/713e4d3501b73cb09e2d8ff1550ce3f08e719bc1/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f35393432372f2545412542302538302545432538342541342e504e47)\n",
        "\n",
        "$f$는 특성의 수, $c$는 클래스의 개수이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZaMLOYP_MfU"
      },
      "source": [
        "###4.2.3 붓꽃 품종 분류를 행렬 연산으로 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9xn8tNaLm7f"
      },
      "source": [
        "|SepalLengthCm$(x_1)$|SepalWidthCm$(x_2)$|PetalLengthCm$(x_3)$|PetalWidthCm$(x_4)$|Species$(y)$|\n",
        "|---|---|---|---|---|\n",
        "|5.1|3.5|1.4|0.2|setosa|\n",
        "|4.9|3.0|1.4|0.2|setosa|\n",
        "|5.8|2.6|4.0|1.2|versicolor|\n",
        "|6.7|3.0|5.2|2.3|virginica|\n",
        "|5.6|2.8|4.9|2.0|virginica|\n",
        "\n",
        "우선 위 예제 데이터는 샘플의 수 5개, 특성의 수 4개로 5 x 4 행렬 $X$로 정의하자\n",
        "\n",
        "$X=\n",
        "\\left(\n",
        "    \\begin{array}{c}\n",
        "      5.1\\ 3.5\\ 1.4\\ 0.2\\ \\\\\n",
        "      4.9\\ 3.0\\ 1.4\\ 0.2\\ \\\\\n",
        "      5.8\\ 2.6\\ 4.0\\ 1.2\\ \\\\\n",
        "      6.7\\ 3.0\\ 5.2\\ 2.3\\ \\\\\n",
        "      5.6\\ 2.8\\ 4.9\\ 2.0\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)$\n",
        "\n",
        "각 행렬의 원소 위치를 반영한 변수로 표현하면\n",
        "\n",
        "$X=\\left(\n",
        "    \\begin{array}{c}\n",
        "      x_{11}\\ x_{12}\\ x_{13}\\ x_{14}\\ \\\\\n",
        "      x_{21}\\ x_{22}\\ x_{23}\\ x_{24}\\ \\\\\n",
        "      x_{31}\\ x_{32}\\ x_{33}\\ x_{34}\\ \\\\\n",
        "      x_{41}\\ x_{42}\\ x_{43}\\ x_{44}\\ \\\\\n",
        "      x_{51}\\ x_{52}\\ x_{53}\\ x_{54}\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)$\n",
        "\n",
        "  이 문제는 선택지가 총 3개인 문제이므로 (=클래스가 총 3개인 문제이므로) 가설의 예측값으로 얻는 행렬 $\\hat{Y}$의 열의 개수는 3개여야 한다. 각 행은 행렬 $X$의 각 행의 예측값이므로 행의 개수는 5개로 동일해야 한다. 행렬 $\\hat{Y}$의 크기는 5 × 3 이다.\n",
        "\n",
        "$\\hat{Y}=\\left(\n",
        "    \\begin{array}{c}\n",
        "      y_{11}\\ y_{12}\\ y_{13}\\ \\\\\n",
        "      y_{21}\\ y_{22}\\ y_{23}\\ \\\\\n",
        "      y_{31}\\ y_{32}\\ y_{33}\\ \\\\\n",
        "      y_{41}\\ y_{42}\\ y_{43}\\ \\\\\n",
        "      y_{51}\\ y_{52}\\ y_{53}\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)$\n",
        "\n",
        "크기 5 × 3의 행렬 $\\hat{Y}$는 \n",
        "\n",
        "크기 5 × 4 입력 행렬 $X$와 \n",
        "\n",
        "가중치 행렬 $W$의 곱으로 얻어지는 행렬이므로 \n",
        "\n",
        "가중치 행렬 $W$은 4 × 3의 크기를 가진 행렬임을 알 수 있다.\n",
        "\n",
        "$W=\\left(\n",
        "    \\begin{array}{c}\n",
        "      w_{11}\\ w_{12}\\ w_{13}\\ \\\\\n",
        "      w_{21}\\ w_{22}\\ w_{23}\\ \\\\\n",
        "      w_{31}\\ w_{32}\\ w_{33}\\ \\\\\n",
        "      w_{41}\\ w_{42}\\ w_{43}\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)$\n",
        "\n",
        "편향 행렬 $B$는 예측값 행렬 $\\hat{Y}$와 크기가 동일해야 하므로 5 × 3의 크기를 가진다.\n",
        "\n",
        "$B=\\left(\n",
        "    \\begin{array}{c}\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "    \\end{array}\n",
        "  \\right)$\n",
        "\n",
        "결과적으로 가설식은 다음과 같다.\n",
        "\n",
        "$\\hat{Y} = softmax(XW + B)$\n",
        "\n",
        "$\\left(\n",
        "    \\begin{array}{c}\n",
        "      y_{11}\\ y_{12}\\ y_{13}\\ \\\\\n",
        "      y_{21}\\ y_{22}\\ y_{23}\\ \\\\\n",
        "      y_{31}\\ y_{32}\\ y_{33}\\ \\\\\n",
        "      y_{41}\\ y_{42}\\ y_{43}\\ \\\\\n",
        "      y_{51}\\ y_{52}\\ y_{53}\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)$=$softmax\\left(\n",
        "\\left(\n",
        "    \\begin{array}{c}\n",
        "      x_{11}\\ x_{12}\\ x_{13}\\ x_{14}\\ \\\\\n",
        "      x_{21}\\ x_{22}\\ x_{23}\\ x_{24}\\ \\\\\n",
        "      x_{31}\\ x_{32}\\ x_{33}\\ x_{34}\\ \\\\\n",
        "      x_{41}\\ x_{42}\\ x_{43}\\ x_{44}\\ \\\\\n",
        "      x_{51}\\ x_{52}\\ x_{53}\\ x_{54}\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)\n",
        "\\left(\n",
        "    \\begin{array}{c}\n",
        "      w_{11}\\ w_{12}\\ w_{13}\\ \\\\\n",
        "      w_{21}\\ w_{22}\\ w_{23}\\ \\\\\n",
        "      w_{31}\\ w_{32}\\ w_{33}\\ \\\\\n",
        "      w_{41}\\ w_{42}\\ w_{43}\\ \\\\\n",
        "    \\end{array}\n",
        "  \\right)\n",
        "+\n",
        "\\left(\n",
        "    \\begin{array}{c}\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "      b_{1}\\ b_{2}\\ b_{3}\\\\\n",
        "    \\end{array}\n",
        "  \\right)\n",
        "\\right)$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVL1KM2g_RvG"
      },
      "source": [
        "###4.2.4 비용 함수\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co4EJyCWNXLP"
      },
      "source": [
        "소프트맥스 회귀에서는 비용 함수로 크로스 엔트로피 함수를 사용한다.\n",
        "\n",
        "1) 크로스 엔트로피 함수\n",
        "\n",
        "$y$ : 실제값\n",
        "\n",
        "$k$ : 클래스의 개수\n",
        "\n",
        "$y_j$ : 실제값 원-핫 벡터의 $j$번째 인덱스를 의미\n",
        "\n",
        "$p_j$ : 샘플 데이터가 $j$번째 클래스일 확률 ($\\hat{y}_{j}$로 표현하기도 한다.)\n",
        "\n",
        "$cost(W) = -\\sum_{j=1}^{k}y_{j}\\ log(p_{j})$\n",
        "\n",
        "$c$가 실제값 원-핫 벡터에서 1을 가진 원소의 인덱스라고 한다면, $p_{c}=1$은 $\\hat{y}$가 $y$를 정확하게 예측한 경우가 된다.\n",
        "\n",
        "이를 식에 대입해보면 $-1 log(1) = 0$이 되기 때문에, 결과적으로 $\\hat{y}$가 $y$를 정확하게 예측한 경우의 크로스 엔트로피 함수의 값은 0이 된다. 즉, $-\\sum_{j=1}^{k}y_{j}\\ log(p_{j})$ 이 값을 최소화하는 방향으로 학습해야 한다.\n",
        "\n",
        "이제 이를 $n$개의 전체 데이터에 대한 평균을 구한다고 하면 최종 비용 함수는 다음과 같다.\n",
        "\n",
        "$cost(W) = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ log(p_{j}^{(i)})$\n",
        "\n",
        "2) 이진 분류에서의 크로스 엔트로피 함수\n",
        "\n",
        "로지스틱 회귀에서 배운 크로스 엔트로피 함수식과 달라보이지만, 본질적으로는 동일한 함수식이다. 로지스틱 회귀의 크로스 엔트로피 함수식으로부터 소프트맥스 회귀의 크로스 엔트로피 함수식을 도출해보자.\n",
        "\n",
        "$cost(W) = -(y\\ logH(X) + (1-y)\\ log(1-H(X)))$\n",
        "\n",
        "위의 식은 앞서 로지스틱 회귀에서 배웠던 크로스 엔트로피의 함수식을 보여준다. 위의 식에서 $y$를 $y_1$, $y$−1을 $y_2$로 치환하고 $H(X)$를 $p_1$, 1−$H(X)$를 $p_2$로 치환하면 결과적으로 아래의 식을 얻을 수 있습니다.\n",
        "\n",
        "$-(y_{1}\\ log(p_{1})+y_{2}\\ log(p_{2}))$\n",
        "\n",
        "이 식은 아래와 같이 표현할 수 있다.\n",
        "\n",
        "$-(\\sum_{i=1}^{2}y_{i}\\ log\\ p_{i})$\n",
        "\n",
        "소프트맥스 회귀에서는 k의 값이 고정된 값이 아니므로 2를 k로 변경하면\n",
        "\n",
        "$-(\\sum_{i=1}^{k}y_{i}\\ log\\ p_{i})$\n",
        "\n",
        "위의 식은 결과적으로 소프트맥스 회귀의 식과 동일하다. 역으로 소프트맥스 회귀에서 로지스틱 회귀의 크로스 엔트로피 함수식을 얻는 것은 k를 2로 하고, $y_1$과 $y_2$를 각각 $y$와 1−$y$로 치환하고, $p_1$와 $p_2$를 각각 $H(X)$와 1−$H(X)$로 치환하면 된다.\n",
        "\n",
        "정리하면 소프트맥스 함수의 최종 비용 함수에서 $k$가 2라고 가정하면 결국 로지스틱 회귀의 비용 함수와 같다.\n",
        "\n",
        "$cost(W) = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ log(p_{j}^{(i)}) = -\\frac{1}{n} \\sum_{i=1}^{n} [y^{(i)}log(p^{(i)}) + (1-y^{(i)})log(1-p^{(i)})]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQXJtJPfPIkw"
      },
      "source": [
        "##4.3 소프트맥스 회귀의 비용 함수 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uI00zK--j2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b231bac2-bc2e-4f9d-cb69-71052db29226"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4acf0beb10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW99WqNFPf5C"
      },
      "source": [
        "###4.3.1 파이토치로 소프트맥스 회귀의 비용 함수 구현하기 (로우-레벨)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjt_quHwPqtp"
      },
      "source": [
        "z = torch.FloatTensor([1,2,3])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYGaE_RzPwF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d0daf7-a0b6-4aa7-c79a-f387c0d979bf"
      },
      "source": [
        "hypothesis = F.softmax(z, dim=0)\n",
        "print(hypothesis)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0900, 0.2447, 0.6652])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "argQp_reP9l6"
      },
      "source": [
        "$p_{i}=\\frac{e^{z_{i}}}{\\sum_{j=1}^{k} e^{z_{j}}}\\ \\ for\\ i=1, 2, ... k$\n",
        "\n",
        "$softmax(z)=[\\frac{e^{z_{1}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{2}}}{\\sum_{j=1}^{3} e^{z_{j}}}\\ \\frac{e^{z_{3}}}{\\sum_{j=1}^{3} e^{z_{j}}}] = [p_{1}, p_{2}, p_{3}] = \\hat{y} = \\text{예측값}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiKU3KQcQJu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46252608-d288-4375-9596-ee237f1d095f"
      },
      "source": [
        "hypothesis.sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2lFJ8YHQM-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0833e436-a343-400a-bb4c-60a4bfb7e079"
      },
      "source": [
        "z = torch.rand(3, 5, requires_grad=True)\n",
        "z"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7576, 0.2793, 0.4031, 0.7347, 0.0293],\n",
              "        [0.7999, 0.3971, 0.7544, 0.5695, 0.4388],\n",
              "        [0.6387, 0.5247, 0.6826, 0.3051, 0.4635]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWmHLo9tQS3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75f8bf9-5238-46a5-ae1d-b6d03794d2f8"
      },
      "source": [
        "hypothesis = F.softmax(z, dim=1) # 각 샘플에 대해 소프트맥스 함수를 적용해야 하므로, 두번째 차원에 대해 소프트맥스 함수를 적용한다는 의미로, dim=1\n",
        "print(hypothesis)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2645, 0.1639, 0.1855, 0.2585, 0.1277],\n",
            "        [0.2430, 0.1624, 0.2322, 0.1930, 0.1694],\n",
            "        [0.2226, 0.1986, 0.2326, 0.1594, 0.1868]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJBth7-dQ1JF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95337d4-bd63-44f4-d3a7-873a80aafa01"
      },
      "source": [
        "# 소프트맥스 함수의 출력값은 결국 예측값이고, 확률이다. 합은 1이다.\n",
        "print(hypothesis[0,:].sum())\n",
        "print(hypothesis[1,:].sum())\n",
        "print(hypothesis[2,:].sum())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n",
            "tensor(1., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWYXy9eYQlZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a867c10-f959-4629-d141-3455811db35a"
      },
      "source": [
        "# 각 샘플에 대해 임의의 레이블을 만든다.\n",
        "y = torch.randint(5, (3,)).long()\n",
        "print(y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFu-kiyoRkAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dda5178-7384-42c6-c5a4-1620717d1927"
      },
      "source": [
        "# 각 레이블에 대해 원-핫 인코딩을 수행한다.\n",
        "# 모든 원소가 0의 값을 가진 3 × 5 텐서 생성\n",
        "y_one_hot = torch.zeros_like(hypothesis) # hypothesis와 같은 크기를 가지고 모든 원소가 0의 값을 가지는 텐서를 만들어라.\n",
        "y_one_hot.scatter_(1, y.unsqueeze(1), 1)\n",
        "\"\"\"\n",
        "y.unsqueeze(1)에서 (3,)의 크기를 가졌던 y텐서는 (3x1) 텐서가 된다. \n",
        "scatter의 첫번째 인자는 dim=1 에 대해 수행하라는 의미\n",
        "세번째 인자에 1을 넣어줌으로서 두번째 인자인 y_unsqueeze(1)이 알려주는 위치에 숫자 1을 넣도록 한다.\n",
        "연산 뒤에 _를 붙이면 In-place Operation (덮어쓰기 연산) 이다.\n",
        "\"\"\"\n",
        "print(y_one_hot)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJUboO4PRjZp"
      },
      "source": [
        "$cost(W) = -\\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ log(p_{j}^{(i)})$\n",
        "\n",
        "마이너스 부호를 뒤로 빼면 다음 식과도 동일하다.\n",
        "\n",
        "$cost(W) = \\frac{1}{n} \\sum_{i=1}^{n} \\sum_{j=1}^{k}y_{j}^{(i)}\\ * (-log(p_{j}^{(i)}))$\n",
        "\n",
        "이를 코드로 구현하면 아래와 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCAP66H8TibI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73335bbf-3187-490b-e6d1-c43e25b1bfe6"
      },
      "source": [
        "cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
        "print(cost)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.4689, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNtj6r9lPl1G"
      },
      "source": [
        "###4.3.2 파이토치로 소프트맥스 회귀의 비용 함수 구현하기 (하이-레벨)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qq4hGNT_eaE"
      },
      "source": [
        "1)  F.softmax() + torch.log() = F.log_softmax()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83m5A86C0KIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60463495-2fc8-4ccb-8739-7dac6d544898"
      },
      "source": [
        "# Low level\n",
        "torch.log(F.softmax(z, dim=1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.3301, -1.8084, -1.6846, -1.3530, -2.0584],\n",
              "        [-1.4147, -1.8174, -1.4602, -1.6450, -1.7758],\n",
              "        [-1.5025, -1.6165, -1.4586, -1.8360, -1.6776]], grad_fn=<LogBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUCw8pSQT1in",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e5f841-ffb8-4bda-f8d1-a8c48ea0a7d1"
      },
      "source": [
        "# High level\n",
        "F.log_softmax(z, dim=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.3301, -1.8084, -1.6846, -1.3530, -2.0584],\n",
              "        [-1.4147, -1.8174, -1.4602, -1.6450, -1.7758],\n",
              "        [-1.5025, -1.6165, -1.4586, -1.8360, -1.6776]],\n",
              "       grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSVIHOMLT6hV"
      },
      "source": [
        "2) F.log_softmax() + F.nll_loss() = F.cross_entropy()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGkmfU8wT2sv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c5f85c-278f-4aef-b57a-0e5a413e5628"
      },
      "source": [
        "# Low level\n",
        "# 첫번째 수식\n",
        "(y_one_hot * -torch.log(F.softmax(z, dim=1))).sum(dim=1).mean()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV87suPGT84k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d42dcc-8b47-4a12-84df-e687f471e9f4"
      },
      "source": [
        "# 두번째 수식\n",
        "(y_one_hot * - F.log_softmax(z, dim=1)).sum(dim=1).mean()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zBUtKIpUCQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15e5ca4-563d-4165-bc34-625777e08b80"
      },
      "source": [
        "# High level\n",
        "# 세번째 수식\n",
        "F.nll_loss(F.log_softmax(z, dim=1), y)\n",
        "# nll : Negative Log Likelihood의 약자"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVP6uhC4UQm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8a88b4-e249-430c-f7fa-06578cc6092f"
      },
      "source": [
        "# 네번째 수식\n",
        "F.cross_entropy(z, y)\n",
        "# 비용 함수에 소프트맥스 함수까지 포함하고 있음을 기억하고 있어야 구현 시 혼동하지 않는다."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4689, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnZtyablUjp5"
      },
      "source": [
        "##4.4 소프트맥스 회귀 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_orNmGiUSVn"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfq-YJKzUt2m"
      },
      "source": [
        "\"\"\"\n",
        "x_train : 8 x 4 \n",
        "y_trian : 8 x 1, 3개의 클래스\n",
        "\"\"\"\n",
        "\n",
        "x_train = [[1, 2, 1, 1],\n",
        "           [2, 1, 3, 2],\n",
        "           [3, 1, 3, 4],\n",
        "           [4, 1, 5, 5],\n",
        "           [1, 7, 5, 5],\n",
        "           [1, 2, 5, 6],\n",
        "           [1, 6, 6, 6],\n",
        "           [1, 7, 7, 7]]\n",
        "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.LongTensor(y_train)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktlGJJvCVGpg"
      },
      "source": [
        "###4.4.1 소프트맥스 회귀 구현하기(로우-레벨)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4in7IZTiVBZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79776520-bcfd-4922-b4a0-62a776b8de0f"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 4])\n",
            "torch.Size([8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXNE_EnNVNr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c115c661-5d7d-45b5-bf17-c06dcdf81b4d"
      },
      "source": [
        "# y_train은 원-핫 인코딩 시켜줘야 한다.\n",
        "y_one_hot = torch.zeros(8, 3)\n",
        "y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
        "print(y_one_hot.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQGXHt12VZPf"
      },
      "source": [
        "# X가 8x4, Y가 8x3이므로 W는 4x3임을 추정할 수 있다.\n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros((4, 3), requires_grad=True)\n",
        "b = torch.zeros(3, requires_grad=True) # 선형 회귀, 로지스틱 회귀에서는 b가 1이지만 이제는 클래스 개수 만큼이다.\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtBcfE55VpPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bc5042-037f-49dc-a4dd-0e0fb1ce85f9"
      },
      "source": [
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # 가설\n",
        "    hypothesis = F.softmax(x_train.matmul(W) + b, dim=1) \n",
        "\n",
        "    # 비용 함수\n",
        "    cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}/{nb_epochs}, Cost: {cost.item()}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/1000, Cost: 1.0986123085021973\n",
            "Epoch 100/1000, Cost: 0.704199492931366\n",
            "Epoch 200/1000, Cost: 0.6229994297027588\n",
            "Epoch 300/1000, Cost: 0.5657167434692383\n",
            "Epoch 400/1000, Cost: 0.5152913331985474\n",
            "Epoch 500/1000, Cost: 0.46766147017478943\n",
            "Epoch 600/1000, Cost: 0.42127808928489685\n",
            "Epoch 700/1000, Cost: 0.3754015564918518\n",
            "Epoch 800/1000, Cost: 0.32976555824279785\n",
            "Epoch 900/1000, Cost: 0.2850721776485443\n",
            "Epoch 1000/1000, Cost: 0.2481546401977539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u3w7nf7AGYP"
      },
      "source": [
        "###4.4.2 소프트맥스 회귀 구현하기(하이-레벨)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NIfJ7wHV8II"
      },
      "source": [
        "주의할 점은 F.cross_entropy()는 그 자체로 소프트맥스 함수를 포함하고 있다는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyESSTi7V5bm"
      },
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((4, 3), requires_grad=True)\n",
        "b = torch.zeros(3, requires_grad=True) # 선형 회귀, 로지스틱 회귀에서는 b가 1이지만 이제는 클래스 개수 만큼이다.\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=0.1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He-e8kFbWMEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1999e3c3-e4fd-4fa3-aed4-e8165c213517"
      },
      "source": [
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    z = x_train.matmul(W) + b\n",
        "    cost = F.cross_entropy(z, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}/{nb_epochs}, Cost: {cost.item()}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/1000, Cost: 1.0986123085021973\n",
            "Epoch 100/1000, Cost: 0.7041993141174316\n",
            "Epoch 200/1000, Cost: 0.6229995489120483\n",
            "Epoch 300/1000, Cost: 0.5657168626785278\n",
            "Epoch 400/1000, Cost: 0.5152912139892578\n",
            "Epoch 500/1000, Cost: 0.4676618278026581\n",
            "Epoch 600/1000, Cost: 0.42127811908721924\n",
            "Epoch 700/1000, Cost: 0.37540170550346375\n",
            "Epoch 800/1000, Cost: 0.3297657072544098\n",
            "Epoch 900/1000, Cost: 0.2850726842880249\n",
            "Epoch 1000/1000, Cost: 0.2481546849012375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZwBr8ycWduP"
      },
      "source": [
        "###4.4.3 소프트맥스 회귀 nn.Module로 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOxfA4YtWbdP"
      },
      "source": [
        "# 모델을 선언 및 초기화. 4개의 특성을 가지고 3개의 클래스로 분류. input_dim=4, output_dim=3.\n",
        "model = nn.Linear(4, 3)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5PS9sdrWpr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d7af9f-009b-4a00-b73b-df45995d2565"
      },
      "source": [
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train) # F.cross_entropy() 가 소프트맥스 함수를 포함하고 있어서 가설에 정의하지 않음\n",
        "    \n",
        "    # Cost 계산\n",
        "    cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}/{nb_epochs}, Cost: {cost.item()}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/1000, Cost: 1.8495128154754639\n",
            "Epoch 100/1000, Cost: 0.6898943185806274\n",
            "Epoch 200/1000, Cost: 0.6092585325241089\n",
            "Epoch 300/1000, Cost: 0.5512181520462036\n",
            "Epoch 400/1000, Cost: 0.5001412034034729\n",
            "Epoch 500/1000, Cost: 0.45194709300994873\n",
            "Epoch 600/1000, Cost: 0.40505102276802063\n",
            "Epoch 700/1000, Cost: 0.35873308777809143\n",
            "Epoch 800/1000, Cost: 0.3129115104675293\n",
            "Epoch 900/1000, Cost: 0.2695215344429016\n",
            "Epoch 1000/1000, Cost: 0.241921529173851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4by5SSf_XQFw"
      },
      "source": [
        "###4.4.4 소프트맥스 회귀 클래스로 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA2IhGF7XITJ"
      },
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(4, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzI-ZfX6Xjia"
      },
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0GhbOHEXrpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f62fcfe1-03b4-4b1a-c5b1-82d72e1fdca9"
      },
      "source": [
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train) # F.cross_entropy() 가 소프트맥스 함수를 포함하고 있어서 가설에 정의하지 않음\n",
        "    \n",
        "    # Cost 계산\n",
        "    cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}/{nb_epochs}, Cost: {cost.item()}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/1000, Cost: 1.845719814300537\n",
            "Epoch 100/1000, Cost: 0.6471500396728516\n",
            "Epoch 200/1000, Cost: 0.5688682794570923\n",
            "Epoch 300/1000, Cost: 0.5156992673873901\n",
            "Epoch 400/1000, Cost: 0.4717269837856293\n",
            "Epoch 500/1000, Cost: 0.4324864149093628\n",
            "Epoch 600/1000, Cost: 0.39587947726249695\n",
            "Epoch 700/1000, Cost: 0.36050650477409363\n",
            "Epoch 800/1000, Cost: 0.3252274990081787\n",
            "Epoch 900/1000, Cost: 0.2892173230648041\n",
            "Epoch 1000/1000, Cost: 0.25408586859703064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj0uFqy0AL28"
      },
      "source": [
        "##4.5 소프트맥스 회귀로 MNIST 데이터 분류하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROyukvSwYIMB"
      },
      "source": [
        "MNIST 데이터는 아래의 링크에 공개되어져 있다.\n",
        "\n",
        "링크 : http://yann.lecun.com/exdb/mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T8FD1koAOSd"
      },
      "source": [
        "###4.5.1 MNIST 데이터 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO5iMCbRYTQB"
      },
      "source": [
        "![](https://camo.githubusercontent.com/06d848083b3f0d576769c6117934da8671de378b/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f36303332342f6d6e6973742e706e67)\n",
        "\n",
        "MNIST는 숫자 0부터 9까지의 이미지로 구성된 손글씨 데이터셋이다. 이 데이터는 과거에 우체국에서 편지의 우편 번호를 인식하기 위해서 만들어진 훈련 데이터이다. 총 60,000개의 훈련 데이터와 레이블, 총 10,000개의 테스트 데이터와 레이블로 구성되어져 있다. 레이블은 0부터 9까지 총 10개다. 이 예제는 머신 러닝을 처음 배울 때 접하게 되는 가장 기본적인 예제다.\n",
        "\n",
        "MNIST 문제는 손글씨로 적힌 숫자 이미지가 들어오면, 그 이미지가 무슨 숫자인지 맞추는 문제다. 예를 들어 숫자 5의 이미지가 입력으로 들어오면 이게 숫자 5다! 라는 것을 맞춰야 한다. 이 문제는 사람에게는 굉장히 간단하지만 기계에게는 그렇지가 않다.\n",
        "\n",
        "우선 MNIST 문제를 더 자세히 보자. 각각의 이미지는 아래와 같이 28 픽셀 × 28 픽셀의 이미지다.\n",
        "\n",
        "![](https://camo.githubusercontent.com/e49526e694f6e69b6b2eda80fa919c20d9acbebe/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f36303332342f6d6e6973745f535662635959472e706e67)\n",
        "\n",
        "이 문제를 풀기 위해 여기서는 28 픽셀 × 28 픽셀 = 784 픽셀이므로, 각 이미지를 총 784의 원소를 가진 벡터로 만들어줄거다. 이렇게 되면 총 784개의 특성을 가진 샘플이 되는데, 이는 앞서 우리가 풀었던 그 어떤 문제들보다 특성이 굉장히 많은 샘플이 된다.\n",
        "\n",
        "![](https://camo.githubusercontent.com/d6beaf8cdde9490a7129db3cf0ecfc2df964c665/68747470733a2f2f77696b69646f63732e6e65742f696d616765732f706167652f36303332342f2545422538422541342545432539412542342545422541312539432545422539332539432e706e67)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6i1LlwRXvjg"
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC2mgDiIZIy7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381,
          "referenced_widgets": [
            "8ac8771f4d344deda66b645543f259ee",
            "7c720824cc82454c808b74160377fe31",
            "16c342965a7b4accba92f4ec2fa506b1",
            "2503fbffcbd04f2d85f894a46e088188",
            "7e34a9e3112849f196d3efb7523b1a3d",
            "bf7cf43286664bf7a804e2ed99c89798",
            "ce7617063d3d4adf80c29bf7de7bac19",
            "5d786102db9e4ac6b6e303214bbb7bf9",
            "f3f8634577b54cd0b0f6b9748f7ab8b8",
            "0274179daf9044a5ba92d4759f2ff866",
            "11fd883df4fa4367923aae455d1f4f09",
            "9033e945e6d74836adc8027aa63d8aa9",
            "6832aee30f22483794b63adf8c5a46a9",
            "09a16b2e401f4b2d91534e47451c0c0f",
            "c8270fda94454453bebfca2a1b7e6cf3",
            "b249455092cb42f199e701cecca76379",
            "72dd680eef274d1fbd534aa53c4e712d",
            "b7421a34fc4c4b6fbf2f1e103813051f",
            "f0ce633a1ddd4fe6b485fa8601d6240c",
            "91bc172650e549f9a92f2f66f9962507",
            "946a03f4cccb4ee09a911021f268c3d3",
            "d73277eb273b4855b88b1e95ca0dd636",
            "b441ad75145543e6a60166733a481279",
            "a7f50952210344faabaacc2c167c9194",
            "1180aecfa75844c7ac2f464ae35a3b13",
            "c076a71b525643fdb05d75f7bf3cd45b",
            "3fa3af524073408388a810a0b286862b",
            "5c12749db0564fedb380628ce405c89d",
            "519f459e279e410c80f2538124bea29f",
            "30fda7e772d24a7aa9edb39626bc6d06",
            "33edbb70c4274c6daf627d19c9b26ae2",
            "2b4fc943766847ad8d36952e79580d0d"
          ]
        },
        "outputId": "198587d5-1591-4d53-b913-09f588d0cbc9"
      },
      "source": [
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ac8771f4d344deda66b645543f259ee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3f8634577b54cd0b0f6b9748f7ab8b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72dd680eef274d1fbd534aa53c4e712d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1180aecfa75844c7ac2f464ae35a3b13",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ysf_dbCZL0o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ae6cd6-0da9-4eab-9c7d-1ec5fca1362f"
      },
      "source": [
        "X,y = mnist_train[0]\n",
        "print('X size = ',X.size())\n",
        "print('입력 이미지를 [batch_size × 784]의 크기로 reshape 하면 X size = ',X.view(-1, 28*28).size())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X size =  torch.Size([1, 28, 28])\n",
            "입력 이미지를 [batch_size × 784]의 크기로 reshape 하면 X size =  torch.Size([1, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2An_5GkPAX-l"
      },
      "source": [
        "### 4.5.2 토치비전(torchvision) 소개하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUZ2P8KOZQWp"
      },
      "source": [
        "본격적인 실습에 들어가기에 앞서 토치비전(torchvision)이라는 도구를 설명하겠다. \n",
        "\n",
        "torchvision은 유명한 데이터셋들, 이미 구현되어져 있는 유명한 모델들, 일반적인 이미지 전처리 도구들을 포함하고 있는 패키지다. \n",
        "\n",
        "아래의 링크는 torchvision에 어떤 데이터셋들(datasets)과 모델들(models) 그리고 어떤 전처리 방법들(transforms)을 제공하고 있는지 보여준다.\n",
        "\n",
        "링크 : https://pytorch.org/docs/stable/torchvision/index.html\n",
        "\n",
        "자연어 처리를 위해서는 토치텍스트(torchtext)라는 패키지가 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv5Afu_fZfrA"
      },
      "source": [
        "### 4.5.3 분류기 구현을 위한 사전 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp23N7TgZO84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9278606f-9682-4801-cdbe-0fb365cb1463"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
        "print(\"다음 기기로 학습합니다:\", device)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "다음 기기로 학습합니다: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O47xEv2oZ09j"
      },
      "source": [
        "구글의 Colab에서 '런타임 > 런타임 유형 변경 > 하드웨어 가속기 > GPU'를 선택하면 USE_CUDA의 값이 True가 되면서 '다음 기기로 학습합니다: cuda'라는 출력이 나온다.\n",
        "\n",
        "즉, GPU로 연산하겠다는 의미다. 반면에 '하드웨어 가속기 > None'을 선택하면 USE_CUDA의 값이 False가 되면서 '다음 기기로 학습합니다: cpu'라는 출력이 나온다. 즉, CPU로 연산하겠다는 의미다.\n",
        "\n",
        "위의 방법은 앞으로 자주 쓰이게되므로 기억하자.\n",
        "\n",
        "랜덤 시드를 고정하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31sjJPbjZroM"
      },
      "source": [
        "# for reproducibility\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10LnFeEYaFw1"
      },
      "source": [
        "### 4.5.4 MNIST 분류기 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRn5WiNqaCiQ"
      },
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KknR51Ieb99v"
      },
      "source": [
        "첫번째 인자 root : MNIST 데이터를 다운로드 받을 경로\n",
        "\n",
        "두번째 인자 train : True를 주면 MNIST의 훈련 데이터를 리턴, False를 주면 테스트 데이터를 리턴\n",
        "\n",
        "세번째 인자 transform : 현재 데이터를 파이토치 텐서로 변환\n",
        "\n",
        "네번째 인자 download : 해당 경로에 MNIST 데이터가 없다면 다운로드 받겠다는 의미\n",
        "\n",
        "이렇게 데이터를 다운로드했다면 앞서 미니 배치와 데이터로드 챕터에서 학습했던 데이터로더(DataLoader)를 사용하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXX_kadJqmnv"
      },
      "source": [
        "# hyperparameters를 변수로 두고 시작한다.\n",
        "training_epochs = 15 # nb_epochs의 기능과 같다.\n",
        "batch_size = 100"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mxa4NQhb6Yc"
      },
      "source": [
        "# dataset loader\n",
        "data_loader = DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size, # 배치 크기는 100\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True) # drop_last는 데이터를 배치 크기에 맞게 나눈 후(여기서는 100씩) 나머지(여기서는 100보다 작은 수)를 버린다는 의미다."
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmqt7vM4ccIz"
      },
      "source": [
        "이때 DataLoader에는 4개의 인자가 있다.\n",
        "\n",
        "첫번째 인자 DataLoader : 로드할 대상을 의미\n",
        "\n",
        "두번째 인자 batch_size : 배치 크기\n",
        "\n",
        "세번째 인자 shuffle : 매 에포크마다 미니 배치를 셔플할 것인지의 여부\n",
        "\n",
        "네번째 인자 drop_last : 마지막 배치를 버릴 것인지를 의미합니다.\n",
        "\n",
        "drop_last를 하는 이유 : 예를 들어, 1,000개의 데이터가 있다고 했을 때 배치 크기가 128이라고 해보자. 1,000을 128로 나누면 총 7개가 나오고 나머지로 104개가 남는다. 이때 104개를 마지막 배치로 한다고 하였을 때 128개를 충족하지 못하였으므로 104개를 그냥 버릴 수도 있다. 이때 마지막 배치를 버리려면 drop_last=True를 해주면 된다. 이는 다른 미니 배치보다 개수가 적은 마지막 배치를 경사 하강법에 사용하여 마지막 배치가 상대적으로 과대 평가되는 현상을 막아준다.\n",
        "\n",
        "이제 모델을 설계하자. input_dim은 784이고, output_dim은 10이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUVTn9pKdX18"
      },
      "source": [
        "# MNIST data image of shape 28 * 28 = 784\n",
        "model = nn.Linear(784, 10, bias=True).to(device)\n",
        "# 비용 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss().to(device) # 내부적으로 소프트맥스 함수를 포함하고 있음.\n",
        "# 크라이티어리언, 표준이라는 뜻, 굳이 안써도 되는데 왜쓰는지 모르겠다.\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwghsMwBdgCo"
      },
      "source": [
        "to() 함수는 연산을 어디서 수행할지를 정한다. \n",
        "\n",
        "to() 함수는 모델의 매개변수를 지정한 장치의 메모리로 보낸다. \n",
        "\n",
        "CPU를 사용할 경우에는 필요가 없지만, GPU를 사용하려면 to('cuda')를 해 줄 필요가 있다. \n",
        "\n",
        "아무것도 지정하지 않은 경우에는 CPU 연산이라고 보면 된다.\n",
        "\n",
        "bias는 편향 b를 사용할 것인지를 나타낸다. 기본값은 True이므로 굳이 할 필요는 없지만 명시적으로 True를 해주었다.\n",
        "\n",
        "앞서 소프트맥스 회귀를 배울 때는 torch.nn.functional.cross_entropy()를 사용하였으나 여기서는 torch.nn.CrossEntropyLoss()을 사용하고 있다. \n",
        "\n",
        "둘 다 파이토치에서 제공하는 크로스 엔트로피 함수로 소프트맥스 함수를 포함하고 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhUWXpljdv8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7c7268-9e82-49d3-9af0-3a37c8bcf16e"
      },
      "source": [
        "for epoch in range(training_epochs): # 앞서 training_epochs의 값은 15로 지정함.\n",
        "  avg_cost = 0 \n",
        "  \"\"\"\n",
        "  나는 한 epoch 당 cost를 알고 싶다.(60,000개로 한 바퀴 돌렸을 때의 cost) \n",
        "  근데 여기서 cost는 batch 마다 나온다. (한 배치인 100개를 돌렸을 때의 cost) \n",
        "  그래서 각 배치에서의 cost를 모두 더한 후 batch의 수만큼 나눠줄거다.\n",
        "  \"\"\"\n",
        "  num_batch = len(data_loader) # 60,000개를 100개씩 나누었으니 600개의 batch가 생긴다.\n",
        "    \n",
        "  for X, Y in data_loader:\n",
        "    # 배치 크기가 100이므로 아래의 연산에서 X는 (100, 784)의 텐서가 된다.\n",
        "    X = X.view(-1, 28 * 28).to(device)\n",
        "    # 레이블은 원-핫 인코딩이 된 상태가 아니라 0 ~ 9의 정수.\n",
        "    Y = Y.to(device)\n",
        "    \n",
        "    # H(x) 계산\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # Cost 계산\n",
        "    cost = criterion(hypothesis, Y)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print(f'cost : {cost}')\n",
        "    avg_cost += cost / num_batch\n",
        "\n",
        "  print(f'Epoch : {epoch}, Cost : {avg_cost}')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0, Cost : 0.5349124073982239\n",
            "Epoch : 1, Cost : 0.3593086004257202\n",
            "Epoch : 2, Cost : 0.33108818531036377\n",
            "Epoch : 3, Cost : 0.31657418608665466\n",
            "Epoch : 4, Cost : 0.3071303069591522\n",
            "Epoch : 5, Cost : 0.30020785331726074\n",
            "Epoch : 6, Cost : 0.29489728808403015\n",
            "Epoch : 7, Cost : 0.29083046317100525\n",
            "Epoch : 8, Cost : 0.2874195873737335\n",
            "Epoch : 9, Cost : 0.28458911180496216\n",
            "Epoch : 10, Cost : 0.2818162441253662\n",
            "Epoch : 11, Cost : 0.27991968393325806\n",
            "Epoch : 12, Cost : 0.2778368592262268\n",
            "Epoch : 13, Cost : 0.2760223150253296\n",
            "Epoch : 14, Cost : 0.2744431793689728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNbXhUEyecM9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "8a1e537d-df59-4adc-a3b7-ba6f0830bf28"
      },
      "source": [
        "# 테스트 데이터를 사용하여 모델을 테스트한다.\n",
        "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())\n",
        "\n",
        "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\n",
        "    r = random.randint(0, len(mnist_test) - 1)\n",
        "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
        "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
        "\n",
        "    print('Label: ', Y_single_data.item())\n",
        "    single_prediction = model(X_single_data)\n",
        "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
        "\n",
        "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
        "    plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8867999911308289\n",
            "Label:  1\n",
            "Prediction:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMuUlEQVR4nO3dYahc9ZnH8d8vMXlxk4pxc7kEGzbZoi/iwqbhEoRKcSkb1DdJUKQBaxbi3goqKUbY4II172TdtvSFFFITm65dS6UVo6jbu6EgfWHxKlmTKLu6cmMSbpIJedFEgtXk2Rf3WG7jnTM3c87Mmdzn+4FhZs4z55yHQ345M+c/c/+OCAGY/xY03QCA/iDsQBKEHUiCsANJEHYgiWv6ubPly5fHqlWr+rlLIJXJyUmdOXPGs9Uqhd327ZJ+LGmhpGci4smy169atUoTExNVdgmgxOjoaNta12/jbS+U9LSkOyStkbTF9pputwegt6p8Zl8v6cOI+Cgi/iTpl5I21tMWgLpVCfsNko7NeH68WPYXbI/ZnrA90Wq1KuwOQBU9vxofEbsjYjQiRoeHh3u9OwBtVAn7CUkrZzz/arEMwACqEva3JN1oe7XtxZK+LWl/PW0BqFvXQ28R8bnthyT9p6aH3vZGxJHaOgNQq0rj7BHxqqRXa+oFQA/xdVkgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSqDSLK9CkoaGh0vrw8HDb2pEj5bOLL126tKueBlmlsNuelHRO0kVJn0fEaB1NAahfHWf2v4+IMzVsB0AP8ZkdSKJq2EPSb22/bXtsthfYHrM9YXui1WpV3B2AblUN+60RsU7SHZIetP3Ny18QEbsjYjQiRssumADorUphj4gTxf1pSS9KWl9HUwDq13XYbS+x/ZUvHkvaIOlwXY0BqFeVq/Ejkl60/cV2/iMiXq+lK0DSyy+/XFr/9NNPS+sff/xx29r58+dL12WcfYaI+EjS39XYC4AeYugNSIKwA0kQdiAJwg4kQdiBJPiJKxpz9OjR0vpdd91VWr906VJpffXq1W1r83ForRPO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsaMxrr71WWv/ss88qbX/nzp1ta4yzA5i3CDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZ0VPj4+Nta7t27aq07ZGRkdL6vffeW2n78w1ndiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnF2VNLpb7dv27atbe3kyZOV9v3KK6+U1oeGhiptf77peGa3vdf2aduHZyy73va47Q+K+2W9bRNAVXN5G/8zSbdftmynpAMRcaOkA8VzAAOsY9gj4g1JZy9bvFHSvuLxPkmbau4LQM26vUA3EhFTxeOTktp+Sdn2mO0J2xOtVqvL3QGoqvLV+IgISVFS3x0RoxExOjw8XHV3ALrUbdhP2V4hScX96fpaAtAL3YZ9v6StxeOtkl6qpx0AvdJxnN3285Juk7Tc9nFJ35f0pKRf2d4m6aike3rZJAbXo48+Wlo/duxY19t++umnS+vr1q3retsZdQx7RGxpU/pWzb0A6CG+LgskQdiBJAg7kARhB5Ig7EAS/MQVpU6dOlVaf+aZZ7re9i233FJav//++0vrCxZwrroSHC0gCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9uQ++eST0vqaNWtK6+fOnSut225bu/vuu0vXXbx4cWkdV4YzO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTj7PHfhwoXS+ubNm0vrZ89ePs3flXn44Yfb1nbs2FFp27gynNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2ee5Z599trQ+Pj5eafs33XRTaX3Xrl2Vto/6dDyz295r+7TtwzOWPWH7hO2Dxe3O3rYJoKq5vI3/maTbZ1n+o4hYW9xerbctAHXrGPaIeENSte9MAmhclQt0D9l+t3ibv6zdi2yP2Z6wPdFqtSrsDkAV3Yb9J5K+JmmtpClJP2j3wojYHRGjETE6PDzc5e4AVNVV2CPiVERcjIhLkn4qaX29bQGoW1dht71ixtPNkg63ey2AwdBxnN3285Juk7Tc9nFJ35d0m+21kkLSpKTv9rBHdFD2m/Onnnqq0ravuab8n8jrr79eWr/uuusq7R/16Rj2iNgyy+I9PegFQA/xdVkgCcIOJEHYgSQIO5AEYQeS4CeuV4FLly6V1rdv3962Njk5WbruwoULS+svvPBCaX316tWldQwOzuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7FeBY8eOldafe+65rre9YcOG0vqmTZu63jYGC2d2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfarwOOPP971ukNDQ6X1Tr9Xx/zBmR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcfQC8+eabpfUqY+GdxuiXLFnS9bZxdel4Zre90vbvbL9n+4jt7cXy622P2/6guF/W+3YBdGsub+M/l7QjItZIukXSg7bXSNop6UBE3CjpQPEcwIDqGPaImIqId4rH5yS9L+kGSRsl7Stetk8Sf78IGGBXdIHO9ipJX5f0B0kjETFVlE5KGmmzzpjtCdsTrVarQqsAqphz2G0vlfRrSd+LiD/OrEVESIrZ1ouI3RExGhGjw8PDlZoF0L05hd32Ik0H/RcR8Zti8SnbK4r6Ckmne9MigDp0HHqzbUl7JL0fET+cUdovaaukJ4v7l3rS4Txw4cKF0vrY2Fil9R944IG2tUceeaR0XeQxl3H2b0j6jqRDtg8Wyx7TdMh/ZXubpKOS7ulNiwDq0DHsEfF7SW5T/la97QDoFb4uCyRB2IEkCDuQBGEHkiDsQBL8xLUPpqamSuuHDh0qrU9/1aG9++67r21t0aJFpesiD87sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+x9sGfPnkrrL1hQ/n/ytddeW2n7yIEzO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTh7H6xfv77S+hcvXiytl/1e/uabb660b8wfnNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIm5zM++UtLPJY1ICkm7I+LHtp+Q9E+SWsVLH4uIV3vV6NVs48aNpfWI6FMnyGwuX6r5XNKOiHjH9lckvW17vKj9KCL+rXftAajLXOZnn5I0VTw+Z/t9STf0ujEA9bqiz+y2V0n6uqQ/FIsesv2u7b22l7VZZ8z2hO2JVqs120sA9MGcw257qaRfS/peRPxR0k8kfU3SWk2f+X8w23oRsTsiRiNidHh4uIaWAXRjTmG3vUjTQf9FRPxGkiLiVERcjIhLkn4qqdqvPQD0VMewe3oK0T2S3o+IH85YvmLGyzZLOlx/ewDqMper8d+Q9B1Jh2wfLJY9JmmL7bWaHo6blPTdnnQIoBZzuRr/e0mzTRDOmDpwFeEbdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSTczz9jbLsl6eiMRcslnelbA1dmUHsb1L4keutWnb39dUTM+vff+hr2L+3cnoiI0cYaKDGovQ1qXxK9datfvfE2HkiCsANJNB323Q3vv8yg9jaofUn01q2+9NboZ3YA/dP0mR1AnxB2IIlGwm77dtv/Y/tD2zub6KEd25O2D9k+aHui4V722j5t+/CMZdfbHrf9QXE/6xx7DfX2hO0TxbE7aPvOhnpbaft3tt+zfcT29mJ5o8eupK++HLe+f2a3vVDS/0r6B0nHJb0laUtEvNfXRtqwPSlpNCIa/wKG7W9KOi/p5xHxt8Wyf5V0NiKeLP6jXBYR/zwgvT0h6XzT03gXsxWtmDnNuKRNkv5RDR67kr7uUR+OWxNn9vWSPoyIjyLiT5J+KWljA30MvIh4Q9LZyxZvlLSveLxP0/9Y+q5NbwMhIqYi4p3i8TlJX0wz3uixK+mrL5oI+w2Sjs14flyDNd97SPqt7bdtjzXdzCxGImKqeHxS0kiTzcyi4zTe/XTZNOMDc+y6mf68Ki7QfdmtEbFO0h2SHizerg6kmP4MNkhjp3OaxrtfZplm/M+aPHbdTn9eVRNhPyFp5YznXy2WDYSIOFHcn5b0ogZvKupTX8ygW9yfbrifPxukabxnm2ZcA3Dsmpz+vImwvyXpRturbS+W9G1J+xvo40tsLykunMj2EkkbNHhTUe+XtLV4vFXSSw328hcGZRrvdtOMq+Fj1/j05xHR95ukOzV9Rf7/JP1LEz206etvJP13cTvSdG+Sntf027rPNH1tY5ukv5J0QNIHkv5L0vUD1Nu/Szok6V1NB2tFQ73dqum36O9KOljc7mz62JX01ZfjxtdlgSS4QAckQdiBJAg7kARhB5Ig7EAShB1IgrADSfw/pjXY153aavYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux48RIQbem2W"
      },
      "source": [
        "torch.no_grad() 와 model.eval()\n",
        "\n",
        "공통점 : 범위 안에서는 gradient 계산을 하지 않는다.\n",
        "\n",
        "차이점 : torch.no_grad()는 해당 범위 안에서 gradient 계산을 중지시킴으로써 메모리 사용량을 줄이고 계산 속도를 빨리 한다.\n",
        "\n",
        "model.train()과 model.eval()은 모델이 학습 모드인지, 테스트 모드인지를 정하는 것이다. dropout이나 batchnorm이 있는 모델의 경우 학습할 때와 테스트할 때 모델이 달라지기 때문에 세팅한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u_kuckT0Lyo"
      },
      "source": [
        "##4.6 활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExrrunF70Pxf"
      },
      "source": [
        "출처 : https://github.com/Namsik-Yoon/pytorch_basic/blob/master/4_1_%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4_%ED%9A%8C%EA%B7%80_with_My_data.ipynb\n",
        "\n",
        "sklearn에서 제공하는 미국 삼림 수종 데이터를 바탕으로 소프트맥스 회귀모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhji6hyH0OZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d05190-cb93-4496-8d2a-c39f50ce410a"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_covtype\n",
        "\n",
        "covtype = fetch_covtype()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://ndownloader.figshare.com/files/5976039\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbhLX8KU0ZeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5aed099-60ef-43bd-c509-2b040d8ed8f8"
      },
      "source": [
        "print(covtype.DESCR)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _covtype_dataset:\n",
            "\n",
            "Forest covertypes\n",
            "-----------------\n",
            "\n",
            "The samples in this dataset correspond to 30×30m patches of forest in the US,\n",
            "collected for the task of predicting each patch's cover type,\n",
            "i.e. the dominant species of tree.\n",
            "There are seven covertypes, making this a multiclass classification problem.\n",
            "Each sample has 54 features, described on the\n",
            "`dataset's homepage <https://archive.ics.uci.edu/ml/datasets/Covertype>`__.\n",
            "Some of the features are boolean indicators,\n",
            "while others are discrete or continuous measurements.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    =================   ============\n",
            "    Classes                        7\n",
            "    Samples total             581012\n",
            "    Dimensionality                54\n",
            "    Features                     int\n",
            "    =================   ============\n",
            "\n",
            ":func:`sklearn.datasets.fetch_covtype` will load the covertype dataset;\n",
            "it returns a dictionary-like object\n",
            "with the feature matrix in the ``data`` member\n",
            "and the target values in ``target``.\n",
            "The dataset will be downloaded from the web if necessary.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrZEWflD0bIu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "e73b742c-3727-494a-9c5a-1ab2c911b788"
      },
      "source": [
        "covtype_df = pd.DataFrame(data=covtype['data'])\n",
        "covtype_df"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>258.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>6279.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>390.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>6225.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>3180.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>6121.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>3090.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>6211.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>6172.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581007</th>\n",
              "      <td>2396.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>837.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581008</th>\n",
              "      <td>2391.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>845.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581009</th>\n",
              "      <td>2386.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>854.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581010</th>\n",
              "      <td>2384.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>864.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581011</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>875.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>581012 rows × 54 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0      1     2      3      4       5   ...   48   49   50   51   52   53\n",
              "0       2596.0   51.0   3.0  258.0    0.0   510.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "1       2590.0   56.0   2.0  212.0   -6.0   390.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2       2804.0  139.0   9.0  268.0   65.0  3180.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3       2785.0  155.0  18.0  242.0  118.0  3090.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4       2595.0   45.0   2.0  153.0   -1.0   391.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "...        ...    ...   ...    ...    ...     ...  ...  ...  ...  ...  ...  ...  ...\n",
              "581007  2396.0  153.0  20.0   85.0   17.0   108.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "581008  2391.0  152.0  19.0   67.0   12.0    95.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "581009  2386.0  159.0  17.0   60.0    7.0    90.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "581010  2384.0  170.0  15.0   60.0    5.0    90.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "581011  2383.0  165.0  13.0   60.0    4.0    67.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[581012 rows x 54 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AdiOaQZ0dhf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "20b9d665-95ad-4278-e6c2-6071c2741972"
      },
      "source": [
        "data = covtype_df\n",
        "data = data.apply(\n",
        "    lambda x: (x - x.mean()) / x.std()\n",
        ")\n",
        "data['target'] = covtype['target']-1\n",
        "data"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.297804</td>\n",
              "      <td>-0.935156</td>\n",
              "      <td>-1.482819</td>\n",
              "      <td>-0.053767</td>\n",
              "      <td>-0.796272</td>\n",
              "      <td>-1.180145</td>\n",
              "      <td>0.330743</td>\n",
              "      <td>0.439143</td>\n",
              "      <td>0.142960</td>\n",
              "      <td>3.246280</td>\n",
              "      <td>1.108079</td>\n",
              "      <td>-0.232859</td>\n",
              "      <td>-0.879363</td>\n",
              "      <td>-0.260673</td>\n",
              "      <td>-0.072416</td>\n",
              "      <td>-0.114549</td>\n",
              "      <td>-0.09149</td>\n",
              "      <td>-0.147649</td>\n",
              "      <td>-0.0525</td>\n",
              "      <td>-0.106986</td>\n",
              "      <td>-0.013444</td>\n",
              "      <td>-0.017555</td>\n",
              "      <td>-0.044475</td>\n",
              "      <td>-0.243947</td>\n",
              "      <td>-0.147734</td>\n",
              "      <td>-0.233216</td>\n",
              "      <td>-0.175866</td>\n",
              "      <td>-0.032125</td>\n",
              "      <td>-0.002272</td>\n",
              "      <td>-0.070148</td>\n",
              "      <td>-0.076971</td>\n",
              "      <td>-0.057264</td>\n",
              "      <td>-0.08348</td>\n",
              "      <td>-0.127256</td>\n",
              "      <td>-0.038005</td>\n",
              "      <td>-0.24686</td>\n",
              "      <td>-0.332219</td>\n",
              "      <td>-0.194973</td>\n",
              "      <td>-0.028574</td>\n",
              "      <td>-0.066903</td>\n",
              "      <td>-0.043274</td>\n",
              "      <td>-0.040384</td>\n",
              "      <td>2.010334</td>\n",
              "      <td>-0.234031</td>\n",
              "      <td>-0.214979</td>\n",
              "      <td>-0.315238</td>\n",
              "      <td>-0.290284</td>\n",
              "      <td>-0.05273</td>\n",
              "      <td>-0.057143</td>\n",
              "      <td>-0.014313</td>\n",
              "      <td>-0.022653</td>\n",
              "      <td>-0.165956</td>\n",
              "      <td>-0.156014</td>\n",
              "      <td>-0.123653</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.319234</td>\n",
              "      <td>-0.890479</td>\n",
              "      <td>-1.616361</td>\n",
              "      <td>-0.270188</td>\n",
              "      <td>-0.899196</td>\n",
              "      <td>-1.257105</td>\n",
              "      <td>0.293388</td>\n",
              "      <td>0.590898</td>\n",
              "      <td>0.221341</td>\n",
              "      <td>3.205501</td>\n",
              "      <td>1.108079</td>\n",
              "      <td>-0.232859</td>\n",
              "      <td>-0.879363</td>\n",
              "      <td>-0.260673</td>\n",
              "      <td>-0.072416</td>\n",
              "      <td>-0.114549</td>\n",
              "      <td>-0.09149</td>\n",
              "      <td>-0.147649</td>\n",
              "      <td>-0.0525</td>\n",
              "      <td>-0.106986</td>\n",
              "      <td>-0.013444</td>\n",
              "      <td>-0.017555</td>\n",
              "      <td>-0.044475</td>\n",
              "      <td>-0.243947</td>\n",
              "      <td>-0.147734</td>\n",
              "      <td>-0.233216</td>\n",
              "      <td>-0.175866</td>\n",
              "      <td>-0.032125</td>\n",
              "      <td>-0.002272</td>\n",
              "      <td>-0.070148</td>\n",
              "      <td>-0.076971</td>\n",
              "      <td>-0.057264</td>\n",
              "      <td>-0.08348</td>\n",
              "      <td>-0.127256</td>\n",
              "      <td>-0.038005</td>\n",
              "      <td>-0.24686</td>\n",
              "      <td>-0.332219</td>\n",
              "      <td>-0.194973</td>\n",
              "      <td>-0.028574</td>\n",
              "      <td>-0.066903</td>\n",
              "      <td>-0.043274</td>\n",
              "      <td>-0.040384</td>\n",
              "      <td>2.010334</td>\n",
              "      <td>-0.234031</td>\n",
              "      <td>-0.214979</td>\n",
              "      <td>-0.315238</td>\n",
              "      <td>-0.290284</td>\n",
              "      <td>-0.05273</td>\n",
              "      <td>-0.057143</td>\n",
              "      <td>-0.014313</td>\n",
              "      <td>-0.022653</td>\n",
              "      <td>-0.165956</td>\n",
              "      <td>-0.156014</td>\n",
              "      <td>-0.123653</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.554906</td>\n",
              "      <td>-0.148836</td>\n",
              "      <td>-0.681562</td>\n",
              "      <td>-0.006719</td>\n",
              "      <td>0.318742</td>\n",
              "      <td>0.532212</td>\n",
              "      <td>0.816363</td>\n",
              "      <td>0.742653</td>\n",
              "      <td>-0.196691</td>\n",
              "      <td>3.126963</td>\n",
              "      <td>1.108079</td>\n",
              "      <td>-0.232859</td>\n",
              "      <td>-0.879363</td>\n",
              "      <td>-0.260673</td>\n",
              "      <td>-0.072416</td>\n",
              "      <td>-0.114549</td>\n",
              "      <td>-0.09149</td>\n",
              "      <td>-0.147649</td>\n",
              "      <td>-0.0525</td>\n",
              "      <td>-0.106986</td>\n",
              "      <td>-0.013444</td>\n",
              "      <td>-0.017555</td>\n",
              "      <td>-0.044475</td>\n",
              "      <td>-0.243947</td>\n",
              "      <td>-0.147734</td>\n",
              "      <td>4.287864</td>\n",
              "      <td>-0.175866</td>\n",
              "      <td>-0.032125</td>\n",
              "      <td>-0.002272</td>\n",
              "      <td>-0.070148</td>\n",
              "      <td>-0.076971</td>\n",
              "      <td>-0.057264</td>\n",
              "      <td>-0.08348</td>\n",
              "      <td>-0.127256</td>\n",
              "      <td>-0.038005</td>\n",
              "      <td>-0.24686</td>\n",
              "      <td>-0.332219</td>\n",
              "      <td>-0.194973</td>\n",
              "      <td>-0.028574</td>\n",
              "      <td>-0.066903</td>\n",
              "      <td>-0.043274</td>\n",
              "      <td>-0.040384</td>\n",
              "      <td>-0.497429</td>\n",
              "      <td>-0.234031</td>\n",
              "      <td>-0.214979</td>\n",
              "      <td>-0.315238</td>\n",
              "      <td>-0.290284</td>\n",
              "      <td>-0.05273</td>\n",
              "      <td>-0.057143</td>\n",
              "      <td>-0.014313</td>\n",
              "      <td>-0.022653</td>\n",
              "      <td>-0.165956</td>\n",
              "      <td>-0.156014</td>\n",
              "      <td>-0.123653</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.622767</td>\n",
              "      <td>-0.005869</td>\n",
              "      <td>0.520322</td>\n",
              "      <td>-0.129044</td>\n",
              "      <td>1.227907</td>\n",
              "      <td>0.474492</td>\n",
              "      <td>0.965785</td>\n",
              "      <td>0.742653</td>\n",
              "      <td>-0.536343</td>\n",
              "      <td>3.194928</td>\n",
              "      <td>1.108079</td>\n",
              "      <td>-0.232859</td>\n",
              "      <td>-0.879363</td>\n",
              "      <td>-0.260673</td>\n",
              "      <td>-0.072416</td>\n",
              "      <td>-0.114549</td>\n",
              "      <td>-0.09149</td>\n",
              "      <td>-0.147649</td>\n",
              "      <td>-0.0525</td>\n",
              "      <td>-0.106986</td>\n",
              "      <td>-0.013444</td>\n",
              "      <td>-0.017555</td>\n",
              "      <td>-0.044475</td>\n",
              "      <td>-0.243947</td>\n",
              "      <td>-0.147734</td>\n",
              "      <td>-0.233216</td>\n",
              "      <td>-0.175866</td>\n",
              "      <td>-0.032125</td>\n",
              "      <td>-0.002272</td>\n",
              "      <td>-0.070148</td>\n",
              "      <td>-0.076971</td>\n",
              "      <td>-0.057264</td>\n",
              "      <td>-0.08348</td>\n",
              "      <td>-0.127256</td>\n",
              "      <td>-0.038005</td>\n",
              "      <td>-0.24686</td>\n",
              "      <td>-0.332219</td>\n",
              "      <td>-0.194973</td>\n",
              "      <td>-0.028574</td>\n",
              "      <td>-0.066903</td>\n",
              "      <td>-0.043274</td>\n",
              "      <td>-0.040384</td>\n",
              "      <td>-0.497429</td>\n",
              "      <td>4.272927</td>\n",
              "      <td>-0.214979</td>\n",
              "      <td>-0.315238</td>\n",
              "      <td>-0.290284</td>\n",
              "      <td>-0.05273</td>\n",
              "      <td>-0.057143</td>\n",
              "      <td>-0.014313</td>\n",
              "      <td>-0.022653</td>\n",
              "      <td>-0.165956</td>\n",
              "      <td>-0.156014</td>\n",
              "      <td>-0.123653</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.301376</td>\n",
              "      <td>-0.988769</td>\n",
              "      <td>-1.616361</td>\n",
              "      <td>-0.547770</td>\n",
              "      <td>-0.813426</td>\n",
              "      <td>-1.256463</td>\n",
              "      <td>0.293388</td>\n",
              "      <td>0.540313</td>\n",
              "      <td>0.195214</td>\n",
              "      <td>3.165476</td>\n",
              "      <td>1.108079</td>\n",
              "      <td>-0.232859</td>\n",
              "      <td>-0.879363</td>\n",
              "      <td>-0.260673</td>\n",
              "      <td>-0.072416</td>\n",
              "      <td>-0.114549</td>\n",
              "      <td>-0.09149</td>\n",
              "      <td>-0.147649</td>\n",
              "      <td>-0.0525</td>\n",
              "      <td>-0.106986</td>\n",
              "      <td>-0.013444</td>\n",
              "      <td>-0.017555</td>\n",
              "      <td>-0.044475</td>\n",
              "      <td>-0.243947</td>\n",
              "      <td>-0.147734</td>\n",
              "      <td>-0.233216</td>\n",
              "      <td>-0.175866</td>\n",
              "      <td>-0.032125</td>\n",
              "      <td>-0.002272</td>\n",
              "      <td>-0.070148</td>\n",
              "      <td>-0.076971</td>\n",
              "      <td>-0.057264</td>\n",
              "      <td>-0.08348</td>\n",
              "      <td>-0.127256</td>\n",
              "      <td>-0.038005</td>\n",
              "      <td>-0.24686</td>\n",
              "      <td>-0.332219</td>\n",
              "      <td>-0.194973</td>\n",
              "      <td>-0.028574</td>\n",
              "      <td>-0.066903</td>\n",
              "      <td>-0.043274</td>\n",
              "      <td>-0.040384</td>\n",
              "      <td>2.010334</td>\n",
              "      <td>-0.234031</td>\n",
              "      <td>-0.214979</td>\n",
              "      <td>-0.315238</td>\n",
              "      <td>-0.290284</td>\n",
              "      <td>-0.05273</td>\n",
              "      <td>-0.057143</td>\n",
              "      <td>-0.014313</td>\n",
              "      <td>-0.022653</td>\n",
              "      <td>-0.165956</td>\n",
              "      <td>-0.156014</td>\n",
              "      <td>-0.123653</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581007</th>\n",
              "      <td>-2.012129</td>\n",
              "      <td>-0.023740</td>\n",
              "      <td>0.787407</td>\n",
              "      <td>-0.867696</td>\n",
              "      <td>-0.504653</td>\n",
              "      <td>-1.437960</td>\n",
              "      <td>1.040496</td>\n",
              "      <td>0.692068</td>\n",
              "      <td>-0.640851</td>\n",
              "      <td>-0.863386</td>\n",
              "      <td>-0.902461</td>\n",
              "      <td>-0.232859</td>\n",
              "      <td>1.137185</td>\n",
              "      <td>-0.260673</td>\n",
              "      <td>-0.072416</td>\n",
              "      <td>8.729878</td>\n",
              "      <td>-0.09149</td>\n",
              "      <td>-0.147649</td>\n",
              "      <td>-0.0525</td>\n",
              "      <td>-0.106986</td>\n",
              "      <td>-0.013444</td>\n",
              "      <td>-0.017555</td>\n",
              "      <td>-0.044475</td>\n",
              "      <td>-0.243947</td>\n",
              "      <td>-0.147734</td>\n",
              "      <td>-0.233216</td>\n",
              "      <td>-0.175866</td>\n",
              "      <td>-0.032125</td>\n",
              "      <td>-0.002272</td>\n",
              "      <td>-0.070148</td>\n",
              "      <td>-0.076971</td>\n",
              "      <td>-0.057264</td>\n",
              "      <td>-0.08348</td>\n",
              "      <td>-0.127256</td>\n",
              "      <td>-0.038005</td>\n",
              "      <td>-0.24686</td>\n",
              "      <td>-0.332219</td>\n",
              "      <td>-0.194973</td>\n",
              "      <td>-0.028574</td>\n",
              "      <td>-0.066903</td>\n",
              "      <td>-0.043274</td>\n",
              "      <td>-0.040384</td>\n",
              "      <td>-0.497429</td>\n",
              "      <td>-0.234031</td>\n",
              "      <td>-0.214979</td>\n",
              "      <td>-0.315238</td>\n",
              "      <td>-0.290284</td>\n",
              "      <td>-0.05273</td>\n",
              "      <td>-0.057143</td>\n",
              "      <td>-0.014313</td>\n",
              "      <td>-0.022653</td>\n",
              "      <td>-0.165956</td>\n",
              "      <td>-0.156014</td>\n",
              "      <td>-0.123653</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581008</th>\n",
              "      <td>-2.029987</td>\n",
              "      <td>-0.032675</td>\n",
              "      <td>0.653865</td>\n",
              "      <td>-0.952382</td>\n",
              "      <td>-0.590423</td>\n",
              "      <td>-1.446298</td>\n",
              "      <td>1.040496</td>\n",
              "      <td>0.692068</td>\n",
              "      <td>-0.614724</td>\n",
              "      <td>-0.857344</td>\n",
              "      <td>-0.902461</td>\n",
              "      <td>-0.232859</td>\n",
              "      <td>1.137185</td>\n",
              "      <td>-0.260673</td>\n",
              "      <td>-0.072416</td>\n",
              "      <td>8.729878</td>\n",
              "      <td>-0.09149</td>\n",
              "      <td>-0.147649</td>\n",
              "      <td>-0.0525</td>\n",
              "      <td>-0.106986</td>\n",
              "      <td>-0.013444</td>\n",
              "      <td>-0.017555</td>\n",
              "      <td>-0.044475</td>\n",
              "      <td>-0.243947</td>\n",
              "      <td>-0.147734</td>\n",
              "      <td>-0.233216</td>\n",
              "      <td>-0.175866</td>\n",
              "      <td>-0.032125</td>\n",
              "      <td>-0.002272</td>\n",
              "      <td>-0.070148</td>\n",
              "      <td>-0.076971</td>\n",
              "      <td>-0.057264</td>\n",
              "      <td>-0.08348</td>\n",
              "      <td>-0.127256</td>\n",
              "      <td>-0.038005</td>\n",
              "      <td>-0.24686</td>\n",
              "      <td>-0.332219</td>\n",
              "      <td>-0.194973</td>\n",
              "      <td>-0.028574</td>\n",
              "      <td>-0.066903</td>\n",
              "      <td>-0.043274</td>\n",
              "      <td>-0.040384</td>\n",
              "      <td>-0.497429</td>\n",
              "      <td>-0.234031</td>\n",
              "      <td>-0.214979</td>\n",
              "      <td>-0.315238</td>\n",
              "      <td>-0.290284</td>\n",
              "      <td>-0.05273</td>\n",
              "      <td>-0.057143</td>\n",
              "      <td>-0.014313</td>\n",
              "      <td>-0.022653</td>\n",
              "      <td>-0.165956</td>\n",
              "      <td>-0.156014</td>\n",
              "      <td>-0.123653</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581009</th>\n",
              "      <td>-2.047845</td>\n",
              "      <td>0.029873</td>\n",
              "      <td>0.386779</td>\n",
              "      <td>-0.985316</td>\n",
              "      <td>-0.676193</td>\n",
              "      <td>-1.449504</td>\n",
              "      <td>0.891074</td>\n",
              "      <td>0.894408</td>\n",
              "      <td>-0.327326</td>\n",
              "      <td>-0.850548</td>\n",
              "      <td>-0.902461</td>\n",
              "      <td>-0.232859</td>\n",
              "      <td>1.137185</td>\n",
              "      <td>-0.260673</td>\n",
              "      <td>-0.072416</td>\n",
              "      <td>8.729878</td>\n",
              "      <td>-0.09149</td>\n",
              "      <td>-0.147649</td>\n",
              "      <td>-0.0525</td>\n",
              "      <td>-0.106986</td>\n",
              "      <td>-0.013444</td>\n",
              "      <td>-0.017555</td>\n",
              "      <td>-0.044475</td>\n",
              "      <td>-0.243947</td>\n",
              "      <td>-0.147734</td>\n",
              "      <td>-0.233216</td>\n",
              "      <td>-0.175866</td>\n",
              "      <td>-0.032125</td>\n",
              "      <td>-0.002272</td>\n",
              "      <td>-0.070148</td>\n",
              "      <td>-0.076971</td>\n",
              "      <td>-0.057264</td>\n",
              "      <td>-0.08348</td>\n",
              "      <td>-0.127256</td>\n",
              "      <td>-0.038005</td>\n",
              "      <td>-0.24686</td>\n",
              "      <td>-0.332219</td>\n",
              "      <td>-0.194973</td>\n",
              "      <td>-0.028574</td>\n",
              "      <td>-0.066903</td>\n",
              "      <td>-0.043274</td>\n",
              "      <td>-0.040384</td>\n",
              "      <td>-0.497429</td>\n",
              "      <td>-0.234031</td>\n",
              "      <td>-0.214979</td>\n",
              "      <td>-0.315238</td>\n",
              "      <td>-0.290284</td>\n",
              "      <td>-0.05273</td>\n",
              "      <td>-0.057143</td>\n",
              "      <td>-0.014313</td>\n",
              "      <td>-0.022653</td>\n",
              "      <td>-0.165956</td>\n",
              "      <td>-0.156014</td>\n",
              "      <td>-0.123653</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581010</th>\n",
              "      <td>-2.054988</td>\n",
              "      <td>0.128163</td>\n",
              "      <td>0.119694</td>\n",
              "      <td>-0.985316</td>\n",
              "      <td>-0.710502</td>\n",
              "      <td>-1.449504</td>\n",
              "      <td>0.666942</td>\n",
              "      <td>1.096748</td>\n",
              "      <td>0.012325</td>\n",
              "      <td>-0.842996</td>\n",
              "      <td>-0.902461</td>\n",
              "      <td>-0.232859</td>\n",
              "      <td>1.137185</td>\n",
              "      <td>-0.260673</td>\n",
              "      <td>-0.072416</td>\n",
              "      <td>8.729878</td>\n",
              "      <td>-0.09149</td>\n",
              "      <td>-0.147649</td>\n",
              "      <td>-0.0525</td>\n",
              "      <td>-0.106986</td>\n",
              "      <td>-0.013444</td>\n",
              "      <td>-0.017555</td>\n",
              "      <td>-0.044475</td>\n",
              "      <td>-0.243947</td>\n",
              "      <td>-0.147734</td>\n",
              "      <td>-0.233216</td>\n",
              "      <td>-0.175866</td>\n",
              "      <td>-0.032125</td>\n",
              "      <td>-0.002272</td>\n",
              "      <td>-0.070148</td>\n",
              "      <td>-0.076971</td>\n",
              "      <td>-0.057264</td>\n",
              "      <td>-0.08348</td>\n",
              "      <td>-0.127256</td>\n",
              "      <td>-0.038005</td>\n",
              "      <td>-0.24686</td>\n",
              "      <td>-0.332219</td>\n",
              "      <td>-0.194973</td>\n",
              "      <td>-0.028574</td>\n",
              "      <td>-0.066903</td>\n",
              "      <td>-0.043274</td>\n",
              "      <td>-0.040384</td>\n",
              "      <td>-0.497429</td>\n",
              "      <td>-0.234031</td>\n",
              "      <td>-0.214979</td>\n",
              "      <td>-0.315238</td>\n",
              "      <td>-0.290284</td>\n",
              "      <td>-0.05273</td>\n",
              "      <td>-0.057143</td>\n",
              "      <td>-0.014313</td>\n",
              "      <td>-0.022653</td>\n",
              "      <td>-0.165956</td>\n",
              "      <td>-0.156014</td>\n",
              "      <td>-0.123653</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581011</th>\n",
              "      <td>-2.058560</td>\n",
              "      <td>0.083486</td>\n",
              "      <td>-0.147392</td>\n",
              "      <td>-0.985316</td>\n",
              "      <td>-0.727656</td>\n",
              "      <td>-1.464255</td>\n",
              "      <td>0.704297</td>\n",
              "      <td>1.046163</td>\n",
              "      <td>-0.039929</td>\n",
              "      <td>-0.834689</td>\n",
              "      <td>-0.902461</td>\n",
              "      <td>-0.232859</td>\n",
              "      <td>1.137185</td>\n",
              "      <td>-0.260673</td>\n",
              "      <td>-0.072416</td>\n",
              "      <td>8.729878</td>\n",
              "      <td>-0.09149</td>\n",
              "      <td>-0.147649</td>\n",
              "      <td>-0.0525</td>\n",
              "      <td>-0.106986</td>\n",
              "      <td>-0.013444</td>\n",
              "      <td>-0.017555</td>\n",
              "      <td>-0.044475</td>\n",
              "      <td>-0.243947</td>\n",
              "      <td>-0.147734</td>\n",
              "      <td>-0.233216</td>\n",
              "      <td>-0.175866</td>\n",
              "      <td>-0.032125</td>\n",
              "      <td>-0.002272</td>\n",
              "      <td>-0.070148</td>\n",
              "      <td>-0.076971</td>\n",
              "      <td>-0.057264</td>\n",
              "      <td>-0.08348</td>\n",
              "      <td>-0.127256</td>\n",
              "      <td>-0.038005</td>\n",
              "      <td>-0.24686</td>\n",
              "      <td>-0.332219</td>\n",
              "      <td>-0.194973</td>\n",
              "      <td>-0.028574</td>\n",
              "      <td>-0.066903</td>\n",
              "      <td>-0.043274</td>\n",
              "      <td>-0.040384</td>\n",
              "      <td>-0.497429</td>\n",
              "      <td>-0.234031</td>\n",
              "      <td>-0.214979</td>\n",
              "      <td>-0.315238</td>\n",
              "      <td>-0.290284</td>\n",
              "      <td>-0.05273</td>\n",
              "      <td>-0.057143</td>\n",
              "      <td>-0.014313</td>\n",
              "      <td>-0.022653</td>\n",
              "      <td>-0.165956</td>\n",
              "      <td>-0.156014</td>\n",
              "      <td>-0.123653</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>581012 rows × 55 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0         1         2  ...        52        53  target\n",
              "0      -1.297804 -0.935156 -1.482819  ... -0.156014 -0.123653       4\n",
              "1      -1.319234 -0.890479 -1.616361  ... -0.156014 -0.123653       4\n",
              "2      -0.554906 -0.148836 -0.681562  ... -0.156014 -0.123653       1\n",
              "3      -0.622767 -0.005869  0.520322  ... -0.156014 -0.123653       1\n",
              "4      -1.301376 -0.988769 -1.616361  ... -0.156014 -0.123653       4\n",
              "...          ...       ...       ...  ...       ...       ...     ...\n",
              "581007 -2.012129 -0.023740  0.787407  ... -0.156014 -0.123653       2\n",
              "581008 -2.029987 -0.032675  0.653865  ... -0.156014 -0.123653       2\n",
              "581009 -2.047845  0.029873  0.386779  ... -0.156014 -0.123653       2\n",
              "581010 -2.054988  0.128163  0.119694  ... -0.156014 -0.123653       2\n",
              "581011 -2.058560  0.083486 -0.147392  ... -0.156014 -0.123653       2\n",
              "\n",
              "[581012 rows x 55 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxZPDbuL0fWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ed6a19-04f6-4b02-eb45-371fc6786bc4"
      },
      "source": [
        "X,y = data.values[:,:-1],data.values[:,-1:]\n",
        "print(X.shape,y.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(581012, 54) (581012, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuWeAC5t0gn3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTtgNwiI0jL3"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.x_data = torch.FloatTensor(X)\n",
        "        self.y_data = torch.LongTensor(y)\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        x = self.x_data[idx]\n",
        "        y = self.y_data[idx]\n",
        "        return x,y"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFDkXNO00mHN"
      },
      "source": [
        "dataset = MyDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=True)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCzWBCK80oLu"
      },
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(54, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8mxKzyu0pck"
      },
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlftA0eX0tbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "905c0a90-b000-41da-b968-39a3cec6515d"
      },
      "source": [
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    for x_train,y_train in dataloader:\n",
        "        y_train = y_train.squeeze(1)\n",
        "        # H(x) 계산\n",
        "        hypothesis = model(x_train)\n",
        "        # cost 계산\n",
        "        cost=criterion(hypothesis, y_train)\n",
        "        # cost로 H(x) 개선\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        correct_prediction = torch.argmax(hypothesis,dim=1) == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print(f'Epoch : {epoch}/{nb_epochs}, Cost: {cost.item()}, Accuracy : {accuracy * 100}%')\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0/100, Cost: 2.123645782470703, Accuracy : 7.4418428535038865%\n",
            "Epoch : 1/100, Cost: 2.0605525970458984, Accuracy : 8.781574218776893%\n",
            "Epoch : 2/100, Cost: 2.000481128692627, Accuracy : 11.067929750160065%\n",
            "Epoch : 3/100, Cost: 1.9432928562164307, Accuracy : 15.460782221365479%\n",
            "Epoch : 4/100, Cost: 1.8890197277069092, Accuracy : 21.91073506227066%\n",
            "Epoch : 5/100, Cost: 1.837533712387085, Accuracy : 28.512319883238213%\n",
            "Epoch : 6/100, Cost: 1.788737416267395, Accuracy : 35.447804864615534%\n",
            "Epoch : 7/100, Cost: 1.7425713539123535, Accuracy : 41.95989067351449%\n",
            "Epoch : 8/100, Cost: 1.6989282369613647, Accuracy : 47.141711358801544%\n",
            "Epoch : 9/100, Cost: 1.6576685905456543, Accuracy : 51.110131976620096%\n",
            "Epoch : 10/100, Cost: 1.618679404258728, Accuracy : 53.96205241888291%\n",
            "Epoch : 11/100, Cost: 1.5819408893585205, Accuracy : 56.08335111839342%\n",
            "Epoch : 12/100, Cost: 1.5472657680511475, Accuracy : 57.515851651945226%\n",
            "Epoch : 13/100, Cost: 1.5144914388656616, Accuracy : 58.55145848966975%\n",
            "Epoch : 14/100, Cost: 1.483588695526123, Accuracy : 59.39274920311457%\n",
            "Epoch : 15/100, Cost: 1.454348087310791, Accuracy : 60.08550597922246%\n",
            "Epoch : 16/100, Cost: 1.4268430471420288, Accuracy : 60.61974623587809%\n",
            "Epoch : 17/100, Cost: 1.4007740020751953, Accuracy : 61.06741340970583%\n",
            "Epoch : 18/100, Cost: 1.376114845275879, Accuracy : 61.36585819225765%\n",
            "Epoch : 19/100, Cost: 1.3528615236282349, Accuracy : 61.636936930734656%\n",
            "Epoch : 20/100, Cost: 1.3307422399520874, Accuracy : 61.886157256648744%\n",
            "Epoch : 21/100, Cost: 1.3098325729370117, Accuracy : 62.084259877592885%\n",
            "Epoch : 22/100, Cost: 1.2900176048278809, Accuracy : 62.273756824299674%\n",
            "Epoch : 23/100, Cost: 1.271194338798523, Accuracy : 62.43124066284346%\n",
            "Epoch : 24/100, Cost: 1.2532849311828613, Accuracy : 62.58235630245158%\n",
            "Epoch : 25/100, Cost: 1.2363100051879883, Accuracy : 62.74087282190385%\n",
            "Epoch : 26/100, Cost: 1.2201703786849976, Accuracy : 62.9641040116211%\n",
            "Epoch : 27/100, Cost: 1.2047442197799683, Accuracy : 63.22433960055902%\n",
            "Epoch : 28/100, Cost: 1.1900824308395386, Accuracy : 63.47063399723242%\n",
            "Epoch : 29/100, Cost: 1.1761198043823242, Accuracy : 63.70401988254976%\n",
            "Epoch : 30/100, Cost: 1.1627799272537231, Accuracy : 63.951002733162134%\n",
            "Epoch : 31/100, Cost: 1.1500300168991089, Accuracy : 64.20125573998472%\n",
            "Epoch : 32/100, Cost: 1.1378419399261475, Accuracy : 64.46235189634638%\n",
            "Epoch : 33/100, Cost: 1.1262277364730835, Accuracy : 64.67766586576525%\n",
            "Epoch : 34/100, Cost: 1.1151139736175537, Accuracy : 64.87800596201112%\n",
            "Epoch : 35/100, Cost: 1.1044282913208008, Accuracy : 65.05356171645336%\n",
            "Epoch : 36/100, Cost: 1.094238519668579, Accuracy : 65.21293880332937%\n",
            "Epoch : 37/100, Cost: 1.0844395160675049, Accuracy : 65.37076686884265%\n",
            "Epoch : 38/100, Cost: 1.0750595331192017, Accuracy : 65.52394787026773%\n",
            "Epoch : 39/100, Cost: 1.0660988092422485, Accuracy : 65.67557985033011%\n",
            "Epoch : 40/100, Cost: 1.0574136972427368, Accuracy : 65.82531858206026%\n",
            "Epoch : 41/100, Cost: 1.0491116046905518, Accuracy : 65.96111612152589%\n",
            "Epoch : 42/100, Cost: 1.041126012802124, Accuracy : 66.1037982003814%\n",
            "Epoch : 43/100, Cost: 1.0334233045578003, Accuracy : 66.22410552621977%\n",
            "Epoch : 44/100, Cost: 1.0260313749313354, Accuracy : 66.32875052494613%\n",
            "Epoch : 45/100, Cost: 1.0189188718795776, Accuracy : 66.43029748094705%\n",
            "Epoch : 46/100, Cost: 1.0120341777801514, Accuracy : 66.52100128740886%\n",
            "Epoch : 47/100, Cost: 1.00542151927948, Accuracy : 66.60929550508423%\n",
            "Epoch : 48/100, Cost: 0.9990174174308777, Accuracy : 66.6972454957901%\n",
            "Epoch : 49/100, Cost: 0.9928686022758484, Accuracy : 66.79087523149263%\n",
            "Epoch : 50/100, Cost: 0.9869171380996704, Accuracy : 66.8703916614459%\n",
            "Epoch : 51/100, Cost: 0.9811518788337708, Accuracy : 66.95042443185338%\n",
            "Epoch : 52/100, Cost: 0.9755732417106628, Accuracy : 67.03579272028804%\n",
            "Epoch : 53/100, Cost: 0.9702112674713135, Accuracy : 67.11720239857353%\n",
            "Epoch : 54/100, Cost: 0.9649820327758789, Accuracy : 67.19103908353011%\n",
            "Epoch : 55/100, Cost: 0.9599578976631165, Accuracy : 67.26057293136802%\n",
            "Epoch : 56/100, Cost: 0.9550756812095642, Accuracy : 67.33406538935512%\n",
            "Epoch : 57/100, Cost: 0.9503308534622192, Accuracy : 67.40445980461676%\n",
            "Epoch : 58/100, Cost: 0.9457678198814392, Accuracy : 67.45936400625116%\n",
            "Epoch : 59/100, Cost: 0.941310465335846, Accuracy : 67.52080852030595%\n",
            "Epoch : 60/100, Cost: 0.9369853734970093, Accuracy : 67.58724432541841%\n",
            "Epoch : 61/100, Cost: 0.932822048664093, Accuracy : 67.63767357644936%\n",
            "Epoch : 62/100, Cost: 0.9287341237068176, Accuracy : 67.69774118262617%\n",
            "Epoch : 63/100, Cost: 0.9247834086418152, Accuracy : 67.75367806516905%\n",
            "Epoch : 64/100, Cost: 0.9209422469139099, Accuracy : 67.80582845104747%\n",
            "Epoch : 65/100, Cost: 0.9172117114067078, Accuracy : 67.8619374470751%\n",
            "Epoch : 66/100, Cost: 0.9135890007019043, Accuracy : 67.92114448582818%\n",
            "Epoch : 67/100, Cost: 0.9100365042686462, Accuracy : 67.97226219079813%\n",
            "Epoch : 68/100, Cost: 0.9065921902656555, Accuracy : 68.02957598121898%\n",
            "Epoch : 69/100, Cost: 0.9032769799232483, Accuracy : 68.07776775694822%\n",
            "Epoch : 70/100, Cost: 0.9000424742698669, Accuracy : 68.12768066752494%\n",
            "Epoch : 71/100, Cost: 0.8968548774719238, Accuracy : 68.17914259946438%\n",
            "Epoch : 72/100, Cost: 0.8937724828720093, Accuracy : 68.22251519762071%\n",
            "Epoch : 73/100, Cost: 0.8907656669616699, Accuracy : 68.26416666092955%\n",
            "Epoch : 74/100, Cost: 0.8878265619277954, Accuracy : 68.30926039393334%\n",
            "Epoch : 75/100, Cost: 0.8849719762802124, Accuracy : 68.34936283587948%\n",
            "Epoch : 76/100, Cost: 0.882189154624939, Accuracy : 68.39049795873407%\n",
            "Epoch : 77/100, Cost: 0.8794621229171753, Accuracy : 68.42973983325645%\n",
            "Epoch : 78/100, Cost: 0.8767930865287781, Accuracy : 68.46588366505338%\n",
            "Epoch : 79/100, Cost: 0.8742063045501709, Accuracy : 68.50839569578598%\n",
            "Epoch : 80/100, Cost: 0.8716983199119568, Accuracy : 68.54367896015917%\n",
            "Epoch : 81/100, Cost: 0.869235634803772, Accuracy : 68.58670733134599%\n",
            "Epoch : 82/100, Cost: 0.8668305277824402, Accuracy : 68.62026946087173%\n",
            "Epoch : 83/100, Cost: 0.8644829392433167, Accuracy : 68.65899499493986%\n",
            "Epoch : 84/100, Cost: 0.86215740442276, Accuracy : 68.69290135143508%\n",
            "Epoch : 85/100, Cost: 0.8599091172218323, Accuracy : 68.72852884277776%\n",
            "Epoch : 86/100, Cost: 0.8577192425727844, Accuracy : 68.77035241957137%\n",
            "Epoch : 87/100, Cost: 0.855562686920166, Accuracy : 68.80752893227678%\n",
            "Epoch : 88/100, Cost: 0.8534536957740784, Accuracy : 68.83988626740928%\n",
            "Epoch : 89/100, Cost: 0.8514044284820557, Accuracy : 68.88687324874529%\n",
            "Epoch : 90/100, Cost: 0.8493906855583191, Accuracy : 68.92009115130152%\n",
            "Epoch : 91/100, Cost: 0.8474254012107849, Accuracy : 68.9541696212815%\n",
            "Epoch : 92/100, Cost: 0.8454784154891968, Accuracy : 68.98635484292923%\n",
            "Epoch : 93/100, Cost: 0.8436081409454346, Accuracy : 69.01854006457698%\n",
            "Epoch : 94/100, Cost: 0.8417606353759766, Accuracy : 69.05089739970947%\n",
            "Epoch : 95/100, Cost: 0.839948832988739, Accuracy : 69.08187782696399%\n",
            "Epoch : 96/100, Cost: 0.8381772637367249, Accuracy : 69.1095880980083%\n",
            "Epoch : 97/100, Cost: 0.8364529013633728, Accuracy : 69.13368398587293%\n",
            "Epoch : 98/100, Cost: 0.8347213268280029, Accuracy : 69.16500864009694%\n",
            "Epoch : 99/100, Cost: 0.8330705761909485, Accuracy : 69.19805442916842%\n",
            "Epoch : 100/100, Cost: 0.8314281702041626, Accuracy : 69.22800217551445%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29sYQ789hlfa"
      },
      "source": [
        ""
      ],
      "execution_count": 58,
      "outputs": []
    }
  ]
}