{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Jung0Jin/Pytorch_study/blob/master/3.%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI1e06PZDq9S"
   },
   "source": [
    "2021년 1월 6일 지코바 먹고 다시 봐보자\n",
    "\n",
    "출처 : https://wikidocs.net/57810\n",
    "\n",
    "참고 :  https://github.com/Namsik-Yoon/pytorch_basic/blob/master/3.%20%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80(logistic_Regression).ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aj3OTLJbDbnc"
   },
   "source": [
    "# 3. 로지스틱 회귀(Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWH8G174GeCo"
   },
   "source": [
    "## 3.1 로지스틱 회귀(Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_v8uonrtGX3K"
   },
   "source": [
    "일상 속 풀고자하는 많은 문제 중에서는 두 개의 선택지 중에서 정답을 고르는 문제가 많습니다. \n",
    "\n",
    "예를 들어 시험을 봤는데 이 시험 점수가 합격인지 불합격인지가 궁금할 수도 있고, 어떤 메일을 받았을 때 이게 정상 메일인지 스팸 메일인지를 분류하는 문제도 그렇습니다. \n",
    "\n",
    "이렇게 둘 중 하나를 결정하는 문제를 이진 분류(Binary Classification)라고 합니다. \n",
    "\n",
    "그리고 이진 분류를 풀기 위한 대표적인 알고리즘으로 로지스틱 회귀(Logistic Regression)가 있습니다.\n",
    "\n",
    "* 로지스틱 회귀는 알고리즘의 이름은 회귀이지만 실제로는 분류(Classification) 작업에 사용할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Giyjf8034fhN"
   },
   "source": [
    "### 3.1.1 이진 분류(Binary Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzLeFKp-ENbx"
   },
   "source": [
    "학생들이 시험 성적에 따라서 합격, 불합격이 기재된 데이터가 있다고 가정해봅시다. \n",
    "\n",
    "시험 성적이 $x$라면, 합불 결과는 $y$입니다. \n",
    "\n",
    "이 시험의 커트라인은 공개되지 않았는데 이 데이터로부터 특정 점수를 얻었을 때의 합격, 불합격 여부를 판정하는 모델을 만들고자 합시다.\n",
    "\n",
    "|score$(x)$|result$(y)$|\n",
    "|:----|:----|\n",
    "|45|불합격|\n",
    "|50|불합격|\n",
    "|55|불합격|\n",
    "|60|합격|\n",
    "|65|합격|\n",
    "|70|합격|\n",
    "\n",
    "위의 데이터에서 합격을 1, 불합격을 0이라고 하였을 때 그래프를 그려보면 아래와 같습니다.\n",
    "\n",
    "![대체 텍스트](https://wikidocs.net/images/page/22881/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%80.PNG)\n",
    "\n",
    "이러한 점들을 표현하는 그래프는 알파벳의 S자 형태로 표현됩니다. \n",
    "\n",
    "이러한 $x$와 $y$의 관계를 표현하기 위해서는 $Wx+b$와 같은 직선 함수가 아니라 S자 형태로 표현할 수 있는 함수가 필요합니다. \n",
    "\n",
    "이런 문제에 직선을 사용할 경우 분류 작업이 잘 동작하지 않습니다.\n",
    "\n",
    "그래서 이번 로지스틱 회귀의 가설은 선형 회귀 때의 $H(x)=Wx+b$가 아니라, 위와 같이 S자 모양의 그래프를 만들 수 있는 어떤 특정 함수 $f$를 추가적으로 사용하여 $H(x)=f(Wx+b)$의 가설을 사용할 겁니다. \n",
    "\n",
    "그리고 위와 같이 S자 모양의 그래프를 그릴 수 있는 어떤 함수 $f$가 이미 널리 알려져있습니다. \n",
    "\n",
    "바로 시그모이드 함수입니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkAwNGde46HO"
   },
   "source": [
    "### 3.1.2 시그모이드 함수(Sigmoid function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr1fPJGaGlRz"
   },
   "source": [
    "위와 같이 S자 형태로 그래프를 그려주는 시그모이드 함수의 방정식은 아래와 같다.\n",
    "\n",
    "$H(x) = sigmoid(Wx + b) = \\frac{1}{1 + e^{-(Wx + b)}} = σ(Wx + b)$\n",
    "\n",
    "선형 회귀의 목표는 최적의 $W$와 $b$를 찾는 것이었다.\n",
    "\n",
    "$W$는 직선의 기울기를, $b$는 y절편을 의미했다.\n",
    "\n",
    "여기에서는 어떤 영향을 주는지 알아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fhObBUdXHJDL"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f1puWgY4HQOR"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUHm0sEAKrqV"
   },
   "source": [
    "1) W가 1이고 b가 0인 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "a1sq5WPvHVDx",
    "outputId": "db1a2490-c0f2-4545-bf79-78e17c4d48db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = sigmoid(x)\n",
    "\n",
    "plt.plot(x, y, 'g')\n",
    "plt.plot([0,0], [1.0, 0.0], ':') # 가운데 점선 추가\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unNNvxqmLOkb"
   },
   "source": [
    "위 그래프를 통해 시그모이드 함수는 출력값을 0과 1사이의 값으로 저장하여 반환함을 알 수 있다.\n",
    "\n",
    "$x$가 0일 때 0.5의 값을, 매우 작을 때 0에 수렴, 매우 클 때 1에 수렴한다.\n",
    "\n",
    "2) W값의 변화에 따른 경사도의 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "PG0PCOAVLD3F",
    "outputId": "5a98708f-3c8d-4c6f-eaf8-ed7f674a5ac3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y1 = sigmoid(0.5 * x)\n",
    "y2 = sigmoid(x)\n",
    "y3 = sigmoid(2 * x)\n",
    "\n",
    "plt.plot(x, y1, 'r', linestyle='--') # W의 값이 0.5\n",
    "plt.plot(x, y2, 'g') # W의 값이 1\n",
    "plt.plot(x, y3, 'b', linestyle='--') # W의 값이 2\n",
    "plt.plot([0,0], [1.0, 0.0], ':') # 가운데 점선 추가\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xg6OuOeHMQhC"
   },
   "source": [
    "위 그래프에서 $W$ 값이 0.5일 때 빨간색, 1일 때 초록색, 2일 때 파란색이 나오도록 하였다.\n",
    "\n",
    "$W$ 갑에 따라 그래프의 경사도가 변하는 것을 볼 수 있다.\n",
    "\n",
    "선형 회귀에서의 가중치 $W$ 는 직선의 기울기, 여기서는 그래프의 경사도 라는 것을 기억하자.\n",
    "\n",
    "3) b값의 변화에 따른 좌, 우 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "cxNrcG0aMJbY",
    "outputId": "b0ff1bea-5730-43fc-f8a3-8de3fd6532aa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y1 = sigmoid(x + 0.5)\n",
    "y2 = sigmoid(x + 1)\n",
    "y3 = sigmoid(x + 1.5)\n",
    "\n",
    "plt.plot(x, y1, 'r', linestyle='--') # x + 0.5\n",
    "plt.plot(x, y2, 'g') # x + 1\n",
    "plt.plot(x, y3, 'b', linestyle='--') # x + 1.5\n",
    "plt.plot([0,0], [1.0, 0.0], ':') # 가운데 점선 추가\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttlT5vP1NZFd"
   },
   "source": [
    "위 그래프는 $b$ 값에 따라서 그래프가 좌, 우로 이동하는 것을 보여준다.\n",
    "\n",
    "4) 시그모이드 함수를 이용한 분류\n",
    "\n",
    "시그모이드 함수의 출력값이 0과 1사이의 값을 가지는데 이 특성을 이용하여 분류 작업에 사용할 수 있다.\n",
    "\n",
    "임계값을 0.5라고 정하고 출력값이 0.5이상이면 1(True), 0.5이하면 0(False)로 판단할 수 있다.\n",
    "\n",
    "이를 확률로 생각하면 해당 레이블에 속할 확률이 50%가 넘으면 해당 레이블로 판단하고, 50%보다 낮으면 아니라고 판단하는 것으로도 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0sZ197W5ORL"
   },
   "source": [
    "### 3.1.3 비용 함수(Cost function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqavmGjfOA2F"
   },
   "source": [
    "이제 로지스틱 회귀의 가설이 $H(x)=sigmoid(Wx+b)$ 인 것은 알았다.\n",
    "\n",
    "최적의 $W$ 와 $b$ 를 찾을 수 있는 비용 함수(Cost fuction)을 정의하자.\n",
    "\n",
    "앞서 선형 회귀에서 배운 MSE를 사용하면 어떻게 될까?\n",
    "\n",
    "$cost(W, b) = \\frac{1}{n} \\sum_{i=1}^{n} \\left[y^{(i)} - H(x^{(i)})\\right]^2$\n",
    "\n",
    "위의 비용 함수 수식에서 가설은 이제 $H(x)=Wx+b$가 아니라 $H(x)=sigmoid(Wx+b)$ 이다.\n",
    "\n",
    "그리고 이 비용 함수를 미분하면 선형 회귀 때와 달리 비볼록(non-convex) 형태의 그래프가 나온다.\n",
    "\n",
    "![대체 텍스트](https://wikidocs.net/images/page/22881/%EB%A1%9C%EC%BB%AC%EB%AF%B8%EB%8B%88%EB%A9%88.PNG)\n",
    "\n",
    "위와 같은 그래프에 경사 하강법을 사용할 경우의 문제점은 경사 하강법이 오차가 최소값이 되는 구간에 도착했다고 판단한 그 구간이 실제 오차가 완전히 최소값이 되는 구간이 아닐 수 있다는 점이다.\n",
    "\n",
    "사람이 등산 후에 산을 내려올 때도, 가파른 경사를 내려오다가 넓은 평지가 나오면 순간적으로 다 내려왔다고 착각할 수 있다. 하지만 실제로는 그곳이 다 내려온 것이 아니라 잠깐 평지가 나왔을 뿐이라면 길을 더 찾아서 더 내려가야 한다.\n",
    "\n",
    "모델도 마찬가지로 실제 오차가 최소가 되는 구간을 찾을 수 있도록 도와주어야 한다. 만약, 실제 최소가 되는 구간을 잘못 판단하면 최적의 가중치 $W$가 아닌 다른 값을 택해 모델의 성능이 더 오르지 않는다.\n",
    "\n",
    "이를 전체 함수에 걸쳐 최소값인 글로벌 미니멈(Global Minimum)이 아닌 특정 구역에서의 최소값인 로컬 미니멈(Local Minimum)에 도달했다고 한다. 이는 cost가 최소가 되는 가중치 $W$를 찾는다는 비용 함수의 목적에 맞지 않는다.\n",
    "\n",
    "시그모이드 함수의 특징은 함수의 출력값이 0과 1사이의 값이라는 점이다. 즉, 실제값이 1일 때 예측값이 0에 가까워지면 오차가 커져야 하며, 실제값이 0일 때, 예측값이 1에 가까워지면 오차가 커져야 한다. 그리고 이를 충족하는 함수가 바로 로그 함수이다. 다음은 $y=0.5$에 대칭하는 두 개의 로그 함수 그래프다.\n",
    "\n",
    "![대체 텍스트](https://wikidocs.net/images/page/57805/%EA%B7%B8%EB%9E%98%ED%94%84.PNG)\n",
    "\n",
    "실제값이 1일 때의 그래프를 주황색 선으로 표현하였으며, 실제값이 0일 때의 그래프를 초록색 선으로 표현하였다. 실제값이 1이라고 해보면. 이 경우, 예측값인 $H(x)$의 값이 1이면 오차가 0이므로 당연히 cost는 0이 된다. 반면, $H(x)$가 0으로 수렴하면 cost는 무한대로 발산한다. 실제값이 0인 경우는 그 반대로 이해하면 된다. 이 두 개의 로그 함수를 식으로 표현하면 다음과 같다.\n",
    "\n",
    "$\\text{if } y=1 → \\text{cost}\\left( H(x), y \\right) = -\\log(H(x))$\n",
    "\n",
    "$\\text{if } y=0 → \\text{cost}\\left( H(x), y \\right) = -\\log(1-H(x))$\n",
    "\n",
    "$y$의 실제값이 1일 때 $−logH(x)$ 그래프를 사용하고 $y$의 실제값이 0일 때 $−log(1−H(X))$ 그래프를 사용해야 한다.\n",
    "이는 다음과 같이 하나의 식으로 통합할 수 있다.\n",
    "\n",
    "$\\text{cost}\\left( H(x), y \\right) = -[ylogH(x) + (1-y)log(1-H(x))]$\n",
    "\n",
    "왜 위 식이 두 개의 식을 통합한 식이라고 볼 수 있을까? 실제값 $y$가 1이라고하면 덧셈 기호를 기준으로 우측의 항이 없어진다. 반대로 실제값 $y$가 0이라고 하면 덧셈 기호를 기준으로 좌측의 항이 없어진다. 선형 회귀에서는 모든 오차의 평균을 구해 평균 제곱 오차를 사용했었다. 마찬가지로 여기에서도 모든 오차의 평균을 구한다.\n",
    "\n",
    "$cost(W) = -\\frac{1}{n} \\sum_{i=1}^{n} [y^{(i)}logH(x^{(i)}) + (1-y^{(i)})log(1-H(x^{(i)}))]$\n",
    "\n",
    "정리하면, 위 비용 함수는 실제값 $y$와 예측값 $H(x)$의 차이가 커지면 cost가 커지고, 실제값 $y$와 예측값 $H(x)$의 차이가 작아지면 cost는 작아진다. 이제 위 비용 함수에 대해서 경사 하강법을 수행하면서 최적의 가중치 $W$를 찾아간다.\n",
    "\n",
    "$W := W - α\\frac{∂}{∂W}cost(W)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6R99ulaoQSWd"
   },
   "source": [
    "### 3.1.4 파이토치로 로지스틱 회귀 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRkuYhz2NTLN",
    "outputId": "c08e78e2-4c8f-49e2-c3c1-1ec81aed2c22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f94e782a5d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Cl8j8ToGQjHs"
   },
   "outputs": [],
   "source": [
    "x_data = [[1,2], \n",
    "          [2,3], \n",
    "          [3,1],\n",
    "          [4,3],\n",
    "          [5,3],\n",
    "          [6,2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEQimWMtQ4Fy",
    "outputId": "0911f66b-2416-4b91-866f-6787a59481a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2]) torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-Foe34vRTtk"
   },
   "source": [
    "x_train을 $X$라고 하고, 이와 곱해지는 가중치 벡터를 $W$라고 하면, $XW$가 성립되기 위해서는 $W$ 벡터의 크기는 2x1이어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PU4iDjAwQ-Sx"
   },
   "outputs": [],
   "source": [
    "W = torch.zeros((2,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtAoZR9QRwj-"
   },
   "source": [
    "이제 가설식을 세워보겠다. \n",
    "\n",
    "파이토치에서는 $e^{x}$를 구현하기 위해서 torch.exp(x)를 사용한다.\n",
    "\n",
    "이에 따라 행렬 연산을 사용한 가설식은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "l7JueR7BRspT"
   },
   "outputs": [],
   "source": [
    "hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vc0K7ZilR7WJ",
    "outputId": "01a31411-ea2c-48fc-e6d2-305449121045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis) # 예측값인 H(x) 출력. 지금은 W,b 모두 초기화 된 상태이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWhCBituSQFX"
   },
   "source": [
    "사실 파이토치에서는 시그모이드 함수를 이미 구현하여 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pwbMkLU-R_EQ"
   },
   "outputs": [],
   "source": [
    "hypothesis = torch.sigmoid(x_train.matmul(W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTmw9C8eSXRK",
    "outputId": "5ca3aabf-23c0-4eae-8639-441f6f130d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis) # 예측값인 H(x) 출력 지금은 W,b 모두 초기화 된 상태이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSjbrnKtStGD"
   },
   "source": [
    "이제 아래의 비용 함수값. 즉, 현재 예측값과 실제값 사이의 cost를 구해보겠다.\n",
    "\n",
    "$cost(W) = -\\frac{1}{n} \\sum_{i=1}^{n} [y^{(i)}logH(x^{(i)}) + (1-y^{(i)})log(1-H(x^{(i)}))]$\n",
    "\n",
    "우선, 현재 예측값과 실제값을 출력해보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RbZyLE7XSZVR",
    "outputId": "3473ba83-9b0b-4f18-bf00-a1ac30d0015d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1762wfHS0MA",
    "outputId": "877b7e37-2b79-40c7-ad4f-07dd61f3fb8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6931], grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(y_train[0] * torch.log(hypothesis[0]) + \n",
    "  (1 - y_train[0]) * torch.log(1 - hypothesis[0])) # 첫 번째 원소에 대해서만 오차를 구해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XW6ACQ7nTAgW",
    "outputId": "a20424fd-03ee-445a-b618-257327ce0e77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931]], grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "losses = -(y_train * torch.log(hypothesis) + \n",
    "           (1 - y_train) * torch.log(1 - hypothesis)) # 모든 원소에 대해 구해보자\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INsxpATATF4l",
    "outputId": "c26ad21c-447c-45b4-f696-56578abd7bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = losses.mean() # 오차에 대한 평균을 구하자\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEZgHa21TUP4"
   },
   "source": [
    "사실 파이토치에서는 로지스틱 회귀의 비용 함수를 이미 구현하여 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3T-QVLpVTS5X",
    "outputId": "428e1b96-ad1e-411f-b720-e48befdaeb9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(hypothesis, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lB82JnpLThgp"
   },
   "source": [
    "이제 전체 코드를 써보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAb8uIuYTeGz",
    "outputId": "14d01be8-99fc-4632-f937-cd4cb4f6b266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0/1000, Cost : 0.6931471824645996\n",
      "Epoch : 100/1000, Cost : 0.134722039103508\n",
      "Epoch : 200/1000, Cost : 0.08064313977956772\n",
      "Epoch : 300/1000, Cost : 0.05790000036358833\n",
      "Epoch : 400/1000, Cost : 0.045299697667360306\n",
      "Epoch : 500/1000, Cost : 0.03726094961166382\n",
      "Epoch : 600/1000, Cost : 0.03167248144745827\n",
      "Epoch : 700/1000, Cost : 0.027555905282497406\n",
      "Epoch : 800/1000, Cost : 0.024394338950514793\n",
      "Epoch : 900/1000, Cost : 0.02188830077648163\n",
      "Epoch : 1000/1000, Cost : 0.019852152094244957\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1,2], \n",
    "          [2,3], \n",
    "          [3,1],\n",
    "          [4,3],\n",
    "          [5,3],\n",
    "          [6,2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "\n",
    "# 모델 초기화\n",
    "W = torch.zeros((2,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "  # Cost 계산\n",
    "  hypothesis = torch.sigmoid(x_train.matmul(W)+b)\n",
    "  cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "  # cost로 H(x) 개선\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # 100번마다 로그 출력\n",
    "  if epoch % 100 == 0:\n",
    "    print(f'Epoch : {epoch}/{nb_epochs}, Cost : {cost.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUN_z0-iUh0k",
    "outputId": "d96b3439-9caa-4303-e18c-d570c6006bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7648e-04],\n",
      "        [3.1608e-02],\n",
      "        [3.8977e-02],\n",
      "        [9.5622e-01],\n",
      "        [9.9823e-01],\n",
      "        [9.9969e-01]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSJ1ROpXUs3F",
    "outputId": "af8afdef-dd3e-4a8c-dae0-9c58b0272efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True]])\n"
     ]
    }
   ],
   "source": [
    "prediction = hypothesis >= torch.FloatTensor([0.5]) # 0.5를 넘으면 True, 넘지 않으면 False\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ObVh_ZjU6ef",
    "outputId": "e687faf6-681f-42ad-d7ac-f13e383d1f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.2530],\n",
      "        [1.5179]], requires_grad=True) tensor([-14.4819], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W, b) # 훈련이 된 W와 b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tV67f2h52Ou"
   },
   "source": [
    "## 3.2 nn.Module로 구현하는 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40HKyKPHVBu4"
   },
   "source": [
    "선형 회귀 모델의 가설식은 $H(x) = Wx + b$\n",
    "\n",
    "구현하기 위해 파이토치의 nn.Linear()를 사용했다.\n",
    "\n",
    "로지스틱 회귀의 가설식은 $H(x) = sigmoid(Wx + b)$\n",
    "\n",
    "구현하기 위해 nn.Linear()의 결과를 nn.Sigmoid()를 거치게 하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUfVKIhnVkN9"
   },
   "source": [
    "###3.2.1 파이토치의 nn.Linear와 nn.Sigmoid로 로지스틱 회귀 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_ncgwWQ1U-f4"
   },
   "outputs": [],
   "source": [
    "x_data = [[1,2], \n",
    "          [2,3], \n",
    "          [3,1],\n",
    "          [4,3],\n",
    "          [5,3],\n",
    "          [6,2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ct2c15pV3nj"
   },
   "source": [
    "nn.Sequential()은 nn.Module 층을 차례로 쌓을 수 있도록 한다.\n",
    "\n",
    "뒤에서 이를 이용해서 인공 신경망을 구현하므로 기억하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "nEL_MvaZV007"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2,1), # input_dim = 2, output_dim = 1\n",
    "    nn.Sigmoid() # 출력은 시그모이드 함수를 거친다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhccczGUWaga",
    "outputId": "fb981069-5185-4941-e5b1-572bf741122a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4020],\n",
       "        [0.4147],\n",
       "        [0.6556],\n",
       "        [0.5948],\n",
       "        [0.6788],\n",
       "        [0.8061]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train) # 현재 W와 b는 랜덤 초기화가 된 상태이다. 지금 출력되는 값은 아무 의미가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N41LfR5-W-sT",
    "outputId": "85c8869a-2c65-407a-ca14-b52ec13aa917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0/1000, Cost : 0.5397130846977234, Accuracy : 83.33333333333334%\n",
      "Epoch : 100/1000, Cost : 0.1342717856168747, Accuracy : 100.0%\n",
      "Epoch : 200/1000, Cost : 0.08048570901155472, Accuracy : 100.0%\n",
      "Epoch : 300/1000, Cost : 0.05782029405236244, Accuracy : 100.0%\n",
      "Epoch : 400/1000, Cost : 0.045251354575157166, Accuracy : 100.0%\n",
      "Epoch : 500/1000, Cost : 0.037228479981422424, Accuracy : 100.0%\n",
      "Epoch : 600/1000, Cost : 0.0316491425037384, Accuracy : 100.0%\n",
      "Epoch : 700/1000, Cost : 0.027538282796740532, Accuracy : 100.0%\n",
      "Epoch : 800/1000, Cost : 0.024380534887313843, Accuracy : 100.0%\n",
      "Epoch : 900/1000, Cost : 0.021877193823456764, Accuracy : 100.0%\n",
      "Epoch : 1000/1000, Cost : 0.019843030720949173, Accuracy : 100.0%\n"
     ]
    }
   ],
   "source": [
    "# 경사 하강법을 사용하여 훈련해보자\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "  # H(x) 계산\n",
    "  hypothesis = model(x_train)\n",
    "\n",
    "  # Cost 계산\n",
    "  cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "  # cost로 H(x) 계산\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # 100번마다 로그 출력\n",
    "  if epoch % 100 == 0:\n",
    "    prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
    "    correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
    "    accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
    "    print(f'Epoch : {epoch}/{nb_epochs}, Cost : {cost.item()}, Accuracy : {accuracy * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xd1jHD0bYQ0F",
    "outputId": "38ca8b99-8f03-4951-fb4f-12c51aff17d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[3.2534, 1.5181]], requires_grad=True), Parameter containing:\n",
      "tensor([-14.4839], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())) # 훈련 후 W와 b의 값을 출력해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAU-NKD_6Eyc"
   },
   "source": [
    "###3.2.2 인공 신경망으로 표현되는 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvxaP4qIZ3I7"
   },
   "source": [
    "사실 로지스틱 회귀는 인공 신경망으로 간주할 수 있다.\n",
    "\n",
    "![대체 텍스트](https://wikidocs.net/images/page/58686/logistic_regression.PNG)\n",
    "\n",
    "위의 인공 신경망 그림에서 각 화살표는 입력과 곱해지는 가중치 또는 편향이다. \n",
    "\n",
    "각 입력에 대해서 검은색 화살표는 가중치, 회색 화살표는 편향이 곱해진다. 각 입력 $x$는 각 입력의 가중치 $w$와 곱해지고, 편향 $b$는 상수 1과 곱해지는 것으로 표현되었다. 그리고 출력하기 전에 시그모이드 함수를 지나게 된다.\n",
    "\n",
    "결과적으로 위의 인공 신경망은 다음과 같은 다중 로지스틱 회귀를 표현하고 있다.\n",
    "\n",
    "$H(x)=sigmoid(x_{1}w_{1} + x_{2}w_{2} + b)$\n",
    "\n",
    "뒤에서 인공 신경망을 배우면서 언급하겠지만, 시그모이드 함수는 인공 신경망의 은닉층에서는 거의 사용되지 않는다.\n",
    "\n",
    "근데 왜 배움? ㅎ...\n",
    "\n",
    "그냥 배우라면 배우자 영진아\n",
    "\n",
    "로지스틱 회귀와 소프트맥스 회귀 : https://hyeonnii.tistory.com/239 참고하시라우\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HxaNqkBaMbJ"
   },
   "source": [
    "##3.3 클래스로 파이토치 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntsHtUDT6VLO"
   },
   "source": [
    "### 3.3.1 모델을 클래스로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "aOb0tht16N0T"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "   nn.Linear(2, 1), # input_dim = 2, output_dim = 1\n",
    "   nn.Sigmoid() # 출력은 시그모이드 함수를 거친다\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-c-79n-F6P21"
   },
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qczrXM4T6Xtz"
   },
   "source": [
    "위와 같은 클래스를 사용한 모델 구현 형식은 대부분의 파이토치 구현체에서 사용하고 있는 방식으로 반드시 숙지할 필요가 있다.\n",
    "\n",
    "클래스(class) 형태의 모델은 nn.Module 을 상속받는다. 그리고 __init__()에서 모델의 구조와 동적을 정의하는 생성자를 정의한다. \n",
    "\n",
    "이는 파이썬에서 객체가 갖는 속성값을 초기화하는 역할로, 객체가 생성될 때 자동으호 호출된다. \n",
    "\n",
    "super() 함수를 부르면 여기서 만든 클래스는 nn.Module 클래스의 속성들을 가지고 초기화 된다. \n",
    "\n",
    "foward() 함수는 모델이 학습데이터를 입력받아서 forward 연산을 진행시키는 함수다. \n",
    "\n",
    "이 forward() 함수는 model 객체를 데이터와 함께 호출하면 자동으로 실행된다. \n",
    "\n",
    "예를 들어 model이란 이름의 객체를 생성 후, model(입력 데이터)와 같은 형식으로 객체를 호출하면 자동으로 forward 연산이 수행된다.\n",
    "\n",
    "$H(x)$ 식에 입력 $x$로부터 예측된 $y$를 얻는 것을 forward 연산이라고 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3BlLjnf6iNV"
   },
   "source": [
    "### 3.3.2 로지스틱 회귀 클래스로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4mo7m496oPG",
    "outputId": "666648a7-fc19-4b8c-c4dc-5c84b3ff22b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 0.539713 Accuracy 83.33%\n",
      "Epoch  100/1000 Cost: 0.134272 Accuracy 100.00%\n",
      "Epoch  200/1000 Cost: 0.080486 Accuracy 100.00%\n",
      "Epoch  300/1000 Cost: 0.057820 Accuracy 100.00%\n",
      "Epoch  400/1000 Cost: 0.045251 Accuracy 100.00%\n",
      "Epoch  500/1000 Cost: 0.037228 Accuracy 100.00%\n",
      "Epoch  600/1000 Cost: 0.031649 Accuracy 100.00%\n",
      "Epoch  700/1000 Cost: 0.027538 Accuracy 100.00%\n",
      "Epoch  800/1000 Cost: 0.024381 Accuracy 100.00%\n",
      "Epoch  900/1000 Cost: 0.021877 Accuracy 100.00%\n",
      "Epoch 1000/1000 Cost: 0.019843 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "\n",
    "model = BinaryClassifier()\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
    "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
    "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9x1nKPZAavE_"
   },
   "source": [
    "#3.4 활용\n",
    "\n",
    "출처 : https://github.com/Namsik-Yoon/pytorch_basic/blob/master/3_1_%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80_with_My_data.ipynb\n",
    "\n",
    " sklearn에서 제공하는 유방암 데이터를 바탕으로 로지스틱 회귀 모델을 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "pgC5pRKTazXg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TD2r02rZbG-K",
    "outputId": "d8dce51f-e4f0-4d0b-96b3-ae33e2544890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "C73nbpp7bIgQ",
    "outputId": "da3f2c3f-99ab-444c-fbb3-c10b7e837eae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
       "0          17.99         10.38  ...          0.4601                  0.11890\n",
       "1          20.57         17.77  ...          0.2750                  0.08902\n",
       "2          19.69         21.25  ...          0.3613                  0.08758\n",
       "3          11.42         20.38  ...          0.6638                  0.17300\n",
       "4          20.29         14.34  ...          0.2364                  0.07678\n",
       "..           ...           ...  ...             ...                      ...\n",
       "564        21.56         22.39  ...          0.2060                  0.07115\n",
       "565        20.13         28.25  ...          0.2572                  0.06637\n",
       "566        16.60         28.08  ...          0.2218                  0.07820\n",
       "567        20.60         29.33  ...          0.4087                  0.12400\n",
       "568         7.76         24.54  ...          0.2871                  0.07039\n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df = pd.DataFrame(data=breast_cancer['data'],columns=breast_cancer['feature_names'])\n",
    "cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "7IlGQAPBbNPy",
    "outputId": "cb4d4332-ac3a-480a-ae2f-e47676ecd63d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.096100</td>\n",
       "      <td>-2.071512</td>\n",
       "      <td>1.268817</td>\n",
       "      <td>0.983510</td>\n",
       "      <td>1.567087</td>\n",
       "      <td>3.280628</td>\n",
       "      <td>2.650542</td>\n",
       "      <td>2.530249</td>\n",
       "      <td>2.215566</td>\n",
       "      <td>2.253764</td>\n",
       "      <td>2.487545</td>\n",
       "      <td>-0.564768</td>\n",
       "      <td>2.830540</td>\n",
       "      <td>2.485391</td>\n",
       "      <td>-0.213814</td>\n",
       "      <td>1.315704</td>\n",
       "      <td>0.723390</td>\n",
       "      <td>0.660239</td>\n",
       "      <td>1.147747</td>\n",
       "      <td>0.906286</td>\n",
       "      <td>1.885031</td>\n",
       "      <td>-1.358098</td>\n",
       "      <td>2.301575</td>\n",
       "      <td>1.999478</td>\n",
       "      <td>1.306537</td>\n",
       "      <td>2.614365</td>\n",
       "      <td>2.107672</td>\n",
       "      <td>2.294058</td>\n",
       "      <td>2.748204</td>\n",
       "      <td>1.935312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.828212</td>\n",
       "      <td>-0.353322</td>\n",
       "      <td>1.684473</td>\n",
       "      <td>1.907030</td>\n",
       "      <td>-0.826235</td>\n",
       "      <td>-0.486643</td>\n",
       "      <td>-0.023825</td>\n",
       "      <td>0.547662</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>-0.867889</td>\n",
       "      <td>0.498816</td>\n",
       "      <td>-0.875473</td>\n",
       "      <td>0.263095</td>\n",
       "      <td>0.741749</td>\n",
       "      <td>-0.604819</td>\n",
       "      <td>-0.692317</td>\n",
       "      <td>-0.440393</td>\n",
       "      <td>0.259933</td>\n",
       "      <td>-0.804742</td>\n",
       "      <td>-0.099356</td>\n",
       "      <td>1.804340</td>\n",
       "      <td>-0.368879</td>\n",
       "      <td>1.533776</td>\n",
       "      <td>1.888827</td>\n",
       "      <td>-0.375282</td>\n",
       "      <td>-0.430066</td>\n",
       "      <td>-0.146620</td>\n",
       "      <td>1.086129</td>\n",
       "      <td>-0.243675</td>\n",
       "      <td>0.280943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.578499</td>\n",
       "      <td>0.455786</td>\n",
       "      <td>1.565126</td>\n",
       "      <td>1.557513</td>\n",
       "      <td>0.941382</td>\n",
       "      <td>1.052000</td>\n",
       "      <td>1.362280</td>\n",
       "      <td>2.035440</td>\n",
       "      <td>0.938859</td>\n",
       "      <td>-0.397658</td>\n",
       "      <td>1.227596</td>\n",
       "      <td>-0.779398</td>\n",
       "      <td>0.850180</td>\n",
       "      <td>1.180298</td>\n",
       "      <td>-0.296744</td>\n",
       "      <td>0.814257</td>\n",
       "      <td>0.212889</td>\n",
       "      <td>1.423575</td>\n",
       "      <td>0.236827</td>\n",
       "      <td>0.293301</td>\n",
       "      <td>1.510541</td>\n",
       "      <td>-0.023953</td>\n",
       "      <td>1.346291</td>\n",
       "      <td>1.455004</td>\n",
       "      <td>0.526944</td>\n",
       "      <td>1.081980</td>\n",
       "      <td>0.854222</td>\n",
       "      <td>1.953282</td>\n",
       "      <td>1.151242</td>\n",
       "      <td>0.201214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768233</td>\n",
       "      <td>0.253509</td>\n",
       "      <td>-0.592166</td>\n",
       "      <td>-0.763792</td>\n",
       "      <td>3.280667</td>\n",
       "      <td>3.399917</td>\n",
       "      <td>1.914213</td>\n",
       "      <td>1.450431</td>\n",
       "      <td>2.864862</td>\n",
       "      <td>4.906602</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>-0.110312</td>\n",
       "      <td>0.286341</td>\n",
       "      <td>-0.288125</td>\n",
       "      <td>0.689095</td>\n",
       "      <td>2.741868</td>\n",
       "      <td>0.818798</td>\n",
       "      <td>1.114027</td>\n",
       "      <td>4.728520</td>\n",
       "      <td>2.045711</td>\n",
       "      <td>-0.281217</td>\n",
       "      <td>0.133866</td>\n",
       "      <td>-0.249720</td>\n",
       "      <td>-0.549538</td>\n",
       "      <td>3.391291</td>\n",
       "      <td>3.889975</td>\n",
       "      <td>1.987839</td>\n",
       "      <td>2.173873</td>\n",
       "      <td>6.040726</td>\n",
       "      <td>4.930672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.748758</td>\n",
       "      <td>-1.150804</td>\n",
       "      <td>1.775011</td>\n",
       "      <td>1.824624</td>\n",
       "      <td>0.280125</td>\n",
       "      <td>0.538866</td>\n",
       "      <td>1.369806</td>\n",
       "      <td>1.427237</td>\n",
       "      <td>-0.009552</td>\n",
       "      <td>-0.561956</td>\n",
       "      <td>1.269426</td>\n",
       "      <td>-0.789549</td>\n",
       "      <td>1.272070</td>\n",
       "      <td>1.189310</td>\n",
       "      <td>1.481763</td>\n",
       "      <td>-0.048477</td>\n",
       "      <td>0.827742</td>\n",
       "      <td>1.143199</td>\n",
       "      <td>-0.360775</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>1.297434</td>\n",
       "      <td>-1.465481</td>\n",
       "      <td>1.337363</td>\n",
       "      <td>1.219651</td>\n",
       "      <td>0.220362</td>\n",
       "      <td>-0.313119</td>\n",
       "      <td>0.612640</td>\n",
       "      <td>0.728618</td>\n",
       "      <td>-0.867590</td>\n",
       "      <td>-0.396751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>2.109139</td>\n",
       "      <td>0.720838</td>\n",
       "      <td>2.058974</td>\n",
       "      <td>2.341795</td>\n",
       "      <td>1.040926</td>\n",
       "      <td>0.218868</td>\n",
       "      <td>1.945573</td>\n",
       "      <td>2.318924</td>\n",
       "      <td>-0.312314</td>\n",
       "      <td>-0.930209</td>\n",
       "      <td>2.779634</td>\n",
       "      <td>0.070963</td>\n",
       "      <td>2.377491</td>\n",
       "      <td>2.601897</td>\n",
       "      <td>1.085429</td>\n",
       "      <td>0.191637</td>\n",
       "      <td>0.665416</td>\n",
       "      <td>2.065360</td>\n",
       "      <td>-1.137415</td>\n",
       "      <td>0.167832</td>\n",
       "      <td>1.899514</td>\n",
       "      <td>0.117596</td>\n",
       "      <td>1.751022</td>\n",
       "      <td>2.013529</td>\n",
       "      <td>0.378033</td>\n",
       "      <td>-0.273077</td>\n",
       "      <td>0.663928</td>\n",
       "      <td>1.627719</td>\n",
       "      <td>-1.358963</td>\n",
       "      <td>-0.708467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1.703356</td>\n",
       "      <td>2.083301</td>\n",
       "      <td>1.614511</td>\n",
       "      <td>1.722326</td>\n",
       "      <td>0.102368</td>\n",
       "      <td>-0.017817</td>\n",
       "      <td>0.692434</td>\n",
       "      <td>1.262558</td>\n",
       "      <td>-0.217473</td>\n",
       "      <td>-1.057681</td>\n",
       "      <td>1.299356</td>\n",
       "      <td>2.258951</td>\n",
       "      <td>1.155840</td>\n",
       "      <td>1.290429</td>\n",
       "      <td>-0.423637</td>\n",
       "      <td>-0.069697</td>\n",
       "      <td>0.251980</td>\n",
       "      <td>0.807720</td>\n",
       "      <td>-0.188995</td>\n",
       "      <td>-0.490124</td>\n",
       "      <td>1.535369</td>\n",
       "      <td>2.045599</td>\n",
       "      <td>1.420690</td>\n",
       "      <td>1.493644</td>\n",
       "      <td>-0.690623</td>\n",
       "      <td>-0.394473</td>\n",
       "      <td>0.236365</td>\n",
       "      <td>0.733182</td>\n",
       "      <td>-0.531387</td>\n",
       "      <td>-0.973122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.701667</td>\n",
       "      <td>2.043775</td>\n",
       "      <td>0.672084</td>\n",
       "      <td>0.577445</td>\n",
       "      <td>-0.839745</td>\n",
       "      <td>-0.038646</td>\n",
       "      <td>0.046547</td>\n",
       "      <td>0.105684</td>\n",
       "      <td>-0.808406</td>\n",
       "      <td>-0.894800</td>\n",
       "      <td>0.184730</td>\n",
       "      <td>-0.257145</td>\n",
       "      <td>0.276450</td>\n",
       "      <td>0.180539</td>\n",
       "      <td>-0.379008</td>\n",
       "      <td>0.660696</td>\n",
       "      <td>0.510377</td>\n",
       "      <td>0.611619</td>\n",
       "      <td>-0.890632</td>\n",
       "      <td>0.036694</td>\n",
       "      <td>0.560868</td>\n",
       "      <td>1.373645</td>\n",
       "      <td>0.578492</td>\n",
       "      <td>0.427529</td>\n",
       "      <td>-0.808876</td>\n",
       "      <td>0.350427</td>\n",
       "      <td>0.326479</td>\n",
       "      <td>0.413705</td>\n",
       "      <td>-1.103578</td>\n",
       "      <td>-0.318129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1.836725</td>\n",
       "      <td>2.334403</td>\n",
       "      <td>1.980781</td>\n",
       "      <td>1.733693</td>\n",
       "      <td>1.524426</td>\n",
       "      <td>3.269267</td>\n",
       "      <td>3.294046</td>\n",
       "      <td>2.656528</td>\n",
       "      <td>2.135315</td>\n",
       "      <td>1.042778</td>\n",
       "      <td>1.156917</td>\n",
       "      <td>0.685485</td>\n",
       "      <td>1.437265</td>\n",
       "      <td>1.008615</td>\n",
       "      <td>-0.172848</td>\n",
       "      <td>2.015943</td>\n",
       "      <td>1.301140</td>\n",
       "      <td>0.785031</td>\n",
       "      <td>0.326346</td>\n",
       "      <td>0.903262</td>\n",
       "      <td>1.959515</td>\n",
       "      <td>2.235958</td>\n",
       "      <td>2.301575</td>\n",
       "      <td>1.651717</td>\n",
       "      <td>1.429169</td>\n",
       "      <td>3.901415</td>\n",
       "      <td>3.194794</td>\n",
       "      <td>2.287972</td>\n",
       "      <td>1.917396</td>\n",
       "      <td>2.217684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-1.806811</td>\n",
       "      <td>1.220718</td>\n",
       "      <td>-1.812793</td>\n",
       "      <td>-1.346604</td>\n",
       "      <td>-3.109349</td>\n",
       "      <td>-1.149741</td>\n",
       "      <td>-1.113893</td>\n",
       "      <td>-1.260710</td>\n",
       "      <td>-0.819349</td>\n",
       "      <td>-0.560539</td>\n",
       "      <td>-0.070217</td>\n",
       "      <td>0.382756</td>\n",
       "      <td>-0.157311</td>\n",
       "      <td>-0.465742</td>\n",
       "      <td>0.049299</td>\n",
       "      <td>-1.162493</td>\n",
       "      <td>-1.056571</td>\n",
       "      <td>-1.911765</td>\n",
       "      <td>0.752168</td>\n",
       "      <td>-0.382418</td>\n",
       "      <td>-1.409652</td>\n",
       "      <td>0.763518</td>\n",
       "      <td>-1.431475</td>\n",
       "      <td>-1.074867</td>\n",
       "      <td>-1.857384</td>\n",
       "      <td>-1.206491</td>\n",
       "      <td>-1.304683</td>\n",
       "      <td>-1.743529</td>\n",
       "      <td>-0.048096</td>\n",
       "      <td>-0.750546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  ...  worst fractal dimension  target\n",
       "0       1.096100     -2.071512  ...                 1.935312       0\n",
       "1       1.828212     -0.353322  ...                 0.280943       0\n",
       "2       1.578499      0.455786  ...                 0.201214       0\n",
       "3      -0.768233      0.253509  ...                 4.930672       0\n",
       "4       1.748758     -1.150804  ...                -0.396751       0\n",
       "..           ...           ...  ...                      ...     ...\n",
       "564     2.109139      0.720838  ...                -0.708467       0\n",
       "565     1.703356      2.083301  ...                -0.973122       0\n",
       "566     0.701667      2.043775  ...                -0.318129       0\n",
       "567     1.836725      2.334403  ...                 2.217684       0\n",
       "568    -1.806811      1.220718  ...                -0.750546       1\n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cancer_df\n",
    "data = data.apply(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "data['target'] = breast_cancer['target']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRiSohFEbO-o",
    "outputId": "c2ce6224-d963-417f-c7ac-a5b9d5fdf8cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569, 1)\n"
     ]
    }
   ],
   "source": [
    "X,y = data.values[:,:-1],data.values[:,-1:]\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "pRWMXnlHbQkJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "iLMAhGypbZiY"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = torch.tensor(X,dtype=torch.float)\n",
    "        self.y_data = torch.tensor(y,dtype=torch.float)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "6YNroa39bbeI"
   },
   "outputs": [],
   "source": [
    "dataset = MyDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "jr8qPJDcbdyc"
   },
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(30, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "j9FnZWBjbfdl"
   },
   "outputs": [],
   "source": [
    "model = BinaryClassifier()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZGjvYxubg1r",
    "outputId": "3889845f-d25b-4123-f024-842ed4b68bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0/1000, Cost : 0.8903037309646606, Accuracy : 25.65905096660808%\n",
      "Epoch : 100/1000, Cost : 0.1307920664548874, Accuracy : 97.01230228471002%\n",
      "Epoch : 200/1000, Cost : 0.10329664498567581, Accuracy : 97.71528998242532%\n",
      "Epoch : 300/1000, Cost : 0.09161856770515442, Accuracy : 98.24253075571178%\n",
      "Epoch : 400/1000, Cost : 0.08478771150112152, Accuracy : 98.41827768014059%\n",
      "Epoch : 500/1000, Cost : 0.0801730677485466, Accuracy : 98.59402460456941%\n",
      "Epoch : 600/1000, Cost : 0.0767846629023552, Accuracy : 98.59402460456941%\n",
      "Epoch : 700/1000, Cost : 0.07415701448917389, Accuracy : 98.59402460456941%\n",
      "Epoch : 800/1000, Cost : 0.07203932106494904, Accuracy : 98.59402460456941%\n",
      "Epoch : 900/1000, Cost : 0.07028315216302872, Accuracy : 98.59402460456941%\n",
      "Epoch : 1000/1000, Cost : 0.06879442185163498, Accuracy : 98.59402460456941%\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "  for x_train, y_train in dataloader:\n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "\n",
    "    # Cost 계산\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    # cost로 H(x) 계산\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  # 100번마다 로그 출력\n",
    "  if epoch % 100 == 0:\n",
    "    prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
    "    correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
    "    accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
    "    print(f'Epoch : {epoch}/{nb_epochs}, Cost : {cost.item()}, Accuracy : {accuracy * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcBtVuhvb2F5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOh8BqiUNJCE3WHt01cjSGg",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "3.로지스틱회귀.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
